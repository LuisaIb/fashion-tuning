{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RayTune - Epochs, Learning Rate, Batch Size Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "import random \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from ray import tune\n",
    "from ray.air import Checkpoint, session\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.basic_variant import BasicVariantGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(40)\n",
    "random.seed(40)\n",
    "np.random.seed(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 39724), started 0:35:52 ago. (Use '!kill 39724' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-94594d8b75673fca\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-94594d8b75673fca\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs\n",
    "\n",
    "# !tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"./data\"):\n",
    "    # transforms\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    # datasets\n",
    "    trainset = torchvision.datasets.FashionMNIST(data_dir,\n",
    "        download=True,\n",
    "        train=True,\n",
    "        transform=transform)\n",
    "    testset = torchvision.datasets.FashionMNIST(data_dir,\n",
    "        download=True,\n",
    "        train=False,\n",
    "        transform=transform)\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data outside the training function\n",
    "data_dir = \"./data\"\n",
    "trainset, testset = load_data(data_dir)\n",
    "\n",
    "# Split the training set into subsets\n",
    "test_abs = int(len(trainset) * 0.8)\n",
    "train_subset, val_subset = random_split(trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "# Create data loaders for subsets\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_subset, batch_size=64, shuffle=True, num_workers=2\n",
    ")\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    val_subset, batch_size=64, shuffle=True, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fashion_mnist(config, trainloader, valloader):\n",
    "    net = FashionCNN() \n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "\n",
    "            if i % 2000 == 1999:\n",
    "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1, running_loss / epoch_steps))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data in valloader:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_steps += 1\n",
    "\n",
    "        tune.report(\n",
    "            mean_accuracy=correct / total,\n",
    "            mean_val_loss=val_loss / val_steps\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 23:05:15,415\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "2023-08-15 23:05:19,540\tINFO tune.py:226 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2023-08-15 23:05:19,544\tINFO tune.py:657 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2023-08-15 23:05:19,546\tWARNING syncer.py:260 -- You are using remote storage, but you don't have `fsspec` installed. This can lead to inefficient syncing behavior. To avoid this, install fsspec with `pip install fsspec`. Depending on your remote storage provider, consider installing the respective fsspec-package (see https://github.com/fsspec).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-08-16 08:25:18</td></tr>\n",
       "<tr><td>Running for: </td><td>09:19:58.99        </td></tr>\n",
       "<tr><td>Memory:      </td><td>12.3/15.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 8.0/12 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  mean_val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_fashion_mnist_6bd66_00003</td><td>RUNNING   </td><td>127.0.0.1:9436</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">    0.000475096</td><td style=\"text-align: right;\">0.541167</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         298.583</td><td style=\"text-align: right;\">       1.62951 </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00004</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.00289238 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00005</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">    0.000164914</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00006</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.000121523</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00007</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.000435055</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00008</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.00356855 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00009</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">    0.000220585</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00010</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">    0.00054965 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00011</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.00121543 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00012</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">    0.000729985</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00013</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">    0.000354025</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00014</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">    0.000345626</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00015</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">    0.00105974 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00016</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">    0.000466114</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00017</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">    0.000337475</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00018</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">    0.000384262</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00019</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.00019456 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00000</td><td>TERMINATED</td><td>127.0.0.1:9436</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.00243686 </td><td style=\"text-align: right;\">0.837833</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         693.586</td><td style=\"text-align: right;\">       0.453342</td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00001</td><td>TERMINATED</td><td>127.0.0.1:9436</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.000131615</td><td style=\"text-align: right;\">0.510083</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         886.625</td><td style=\"text-align: right;\">       2.17948 </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00002</td><td>TERMINATED</td><td>127.0.0.1:9436</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.00699512 </td><td style=\"text-align: right;\">0.865917</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">       31628.8  </td><td style=\"text-align: right;\">       0.367655</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 23:05:34,708\tWARNING worker.py:2006 -- Warning: The actor ImplicitFunc is very large (91 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th style=\"text-align: right;\">  mean_accuracy</th><th style=\"text-align: right;\">  mean_val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_fashion_mnist_6bd66_00000</td><td style=\"text-align: right;\">       0.837833</td><td style=\"text-align: right;\">       0.453342</td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00001</td><td style=\"text-align: right;\">       0.510083</td><td style=\"text-align: right;\">       2.17948 </td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00002</td><td style=\"text-align: right;\">       0.865917</td><td style=\"text-align: right;\">       0.367655</td></tr>\n",
       "<tr><td>train_fashion_mnist_6bd66_00003</td><td style=\"text-align: right;\">       0.541167</td><td style=\"text-align: right;\">       1.62951 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# configuration for hyperparameter tuning \n",
    "config = {\n",
    "    \"epochs\": tune.choice([5, 10, 15]),\n",
    "    \"learning_rate\": tune.loguniform(1e-4, 1e-2), \n",
    "    \"batch_size\": tune.choice([16, 32, 64, 128])\n",
    "}\n",
    "\n",
    "max_num_epochs = 15\n",
    "num_samples = 20\n",
    "\n",
    "# scheduler for early stopping\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"mean_val_loss\",\n",
    "    mode=\"min\",\n",
    "    max_t=max_num_epochs,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2,\n",
    ")\n",
    "\n",
    "# run hyperparameter tuning\n",
    "result = tune.run(\n",
    "    partial(train_fashion_mnist, trainloader=trainloader, valloader=valloader),\n",
    "    resources_per_trial={\"cpu\": 8, \"gpu\": 0},\n",
    "    config=config,\n",
    "    num_samples=num_samples,\n",
    "    storage_path='./tune_runs/',\n",
    "    search_alg=BasicVariantGenerator(random_state=40))\n",
    "\n",
    "# Get the best trial\n",
    "best_trial = result.get_best_trial(\"mean_val_loss\", mode=\"min\")\n",
    "\n",
    "# Get the best configuration and other relevant information\n",
    "best_config = best_trial.config\n",
    "best_metrics = best_trial.metric_analysis\n",
    "\n",
    "print(\"Best trial config:\", best_config)\n",
    "print(\"Best trial metrics:\", best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

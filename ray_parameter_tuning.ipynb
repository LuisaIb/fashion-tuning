{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RayTune - Epochs, Learning Rate, Batch Size Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "import random \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from ray import tune\n",
    "from ray.air import Checkpoint, session\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.basic_variant import BasicVariantGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(40)\n",
    "random.seed(40)\n",
    "np.random.seed(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 25732), started 0:15:31 ago. (Use '!kill 25732' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-94594d8b75673fca\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-94594d8b75673fca\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs\n",
    "\n",
    "# !tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"./data\"):\n",
    "    # transforms\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    # datasets\n",
    "    trainset = torchvision.datasets.FashionMNIST(data_dir,\n",
    "        download=True,\n",
    "        train=True,\n",
    "        transform=transform)\n",
    "    testset = torchvision.datasets.FashionMNIST(data_dir,\n",
    "        download=True,\n",
    "        train=False,\n",
    "        transform=transform)\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data outside the training function\n",
    "data_dir = \"./data\"\n",
    "trainset, testset = load_data(data_dir)\n",
    "\n",
    "# Split the training set into subsets\n",
    "test_abs = int(len(trainset) * 0.8)\n",
    "train_subset, val_subset = random_split(trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "# Create data loaders for subsets\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_subset, batch_size=64, shuffle=True, num_workers=2\n",
    ")\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    val_subset, batch_size=64, shuffle=True, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fashion_mnist(config, trainloader, valloader):\n",
    "    net = FashionCNN() \n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "\n",
    "            if i % 2000 == 1999:\n",
    "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1, running_loss / epoch_steps))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data in valloader:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_steps += 1\n",
    "\n",
    "        tune.report(\n",
    "            mean_accuracy=correct / total,\n",
    "            mean_val_loss=val_loss / val_steps\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(net, device=\"cpu\"):\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=4, shuffle=False, num_workers=2\n",
    "    )\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 15:35:42,719\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "2023-08-10 15:35:55,855\tINFO tune.py:226 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2023-08-10 15:35:55,864\tINFO tune.py:657 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2023-08-10 15:35:55,878\tWARNING syncer.py:260 -- You are using remote storage, but you don't have `fsspec` installed. This can lead to inefficient syncing behavior. To avoid this, install fsspec with `pip install fsspec`. Depending on your remote storage provider, consider installing the respective fsspec-package (see https://github.com/fsspec).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-08-10 16:28:53</td></tr>\n",
       "<tr><td>Running for: </td><td>00:52:56.40        </td></tr>\n",
       "<tr><td>Memory:      </td><td>12.5/15.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=8<br>Bracket: Iter 8.000: -0.4628777676757346 | Iter 4.000: -0.5391082885734578 | Iter 2.000: -0.6784710243661353 | Iter 1.000: -2.25635445308178<br>Logical resource usage: 8.0/12 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  mean_val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_fashion_mnist_cb63b_00000</td><td>TERMINATED</td><td>127.0.0.1:18228</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.00243686 </td><td style=\"text-align: right;\">0.840167</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        869.586 </td><td style=\"text-align: right;\">       0.456345</td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00001</td><td>TERMINATED</td><td>127.0.0.1:18228</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.000131615</td><td style=\"text-align: right;\">0.293333</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         60.6329</td><td style=\"text-align: right;\">       2.27392 </td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00002</td><td>TERMINATED</td><td>127.0.0.1:18228</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.00699512 </td><td style=\"text-align: right;\">0.868   </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">       1349.23  </td><td style=\"text-align: right;\">       0.364755</td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00003</td><td>TERMINATED</td><td>127.0.0.1:18228</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">    0.000475096</td><td style=\"text-align: right;\">0.26425 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        143.138 </td><td style=\"text-align: right;\">       2.2675  </td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00004</td><td>TERMINATED</td><td>127.0.0.1:18228</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.00289238 </td><td style=\"text-align: right;\">0.75275 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        134.507 </td><td style=\"text-align: right;\">       0.687719</td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00005</td><td>TERMINATED</td><td>127.0.0.1:18228</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">    0.000164914</td><td style=\"text-align: right;\">0.238167</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         60.1766</td><td style=\"text-align: right;\">       2.28834 </td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00006</td><td>TERMINATED</td><td>127.0.0.1:18228</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.000121523</td><td style=\"text-align: right;\">0.145   </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         61.1182</td><td style=\"text-align: right;\">       2.28819 </td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00007</td><td>TERMINATED</td><td>127.0.0.1:18228</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.000435055</td><td style=\"text-align: right;\">0.4945  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        119.324 </td><td style=\"text-align: right;\">       2.16339 </td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00008</td><td>TERMINATED</td><td>127.0.0.1:18228</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.00356855 </td><td style=\"text-align: right;\">0.803083</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        247.39  </td><td style=\"text-align: right;\">       0.539108</td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00009</td><td>TERMINATED</td><td>127.0.0.1:18228</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">    0.000220585</td><td style=\"text-align: right;\">0.163583</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        105.791 </td><td style=\"text-align: right;\">       2.2707  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 15:36:14,916\tWARNING worker.py:2006 -- Warning: The actor ImplicitFunc is very large (91 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th style=\"text-align: right;\">  mean_accuracy</th><th style=\"text-align: right;\">  mean_val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_fashion_mnist_cb63b_00000</td><td style=\"text-align: right;\">       0.840167</td><td style=\"text-align: right;\">       0.456345</td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00001</td><td style=\"text-align: right;\">       0.293333</td><td style=\"text-align: right;\">       2.27392 </td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00002</td><td style=\"text-align: right;\">       0.868   </td><td style=\"text-align: right;\">       0.364755</td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00003</td><td style=\"text-align: right;\">       0.26425 </td><td style=\"text-align: right;\">       2.2675  </td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00004</td><td style=\"text-align: right;\">       0.75275 </td><td style=\"text-align: right;\">       0.687719</td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00005</td><td style=\"text-align: right;\">       0.238167</td><td style=\"text-align: right;\">       2.28834 </td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00006</td><td style=\"text-align: right;\">       0.145   </td><td style=\"text-align: right;\">       2.28819 </td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00007</td><td style=\"text-align: right;\">       0.4945  </td><td style=\"text-align: right;\">       2.16339 </td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00008</td><td style=\"text-align: right;\">       0.803083</td><td style=\"text-align: right;\">       0.539108</td></tr>\n",
       "<tr><td>train_fashion_mnist_cb63b_00009</td><td style=\"text-align: right;\">       0.163583</td><td style=\"text-align: right;\">       2.2707  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 16:28:53,146\tINFO tune.py:1148 -- Total run time: 3177.28 seconds (3176.29 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"epochs\": tune.choice([5, 10, 15]),\n",
    "    \"learning_rate\": tune.loguniform(1e-4, 1e-2), # 0.0001 to 0.01\n",
    "    \"batch_size\": tune.choice([16, 32, 64, 128])\n",
    "}\n",
    "\n",
    "max_num_epochs = 15\n",
    "num_samples = 10\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"mean_val_loss\",\n",
    "    mode=\"min\",\n",
    "    max_t=max_num_epochs,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2,\n",
    ")\n",
    "\n",
    "result = tune.run(\n",
    "    partial(train_fashion_mnist, trainloader=trainloader, valloader=valloader),\n",
    "    resources_per_trial={\"cpu\": 8, \"gpu\": 0},\n",
    "    config=config,\n",
    "    num_samples=num_samples,\n",
    "    storage_path='./tune_runs/',\n",
    "    search_alg=BasicVariantGenerator(random_state=40),\n",
    "    scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No `mode` has been passed and  `default_mode` has not been set. Please specify the `mode` parameter.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Access the best hyperparameters\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_config \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39;49mget_best_config(metric\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmean_val_loss\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Print the best hyperparameters\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest configuration:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ibele\\anaconda3\\envs\\tuning\\lib\\site-packages\\ray\\tune\\analysis\\experiment_analysis.py:818\u001b[0m, in \u001b[0;36mExperimentAnalysis.get_best_config\u001b[1;34m(self, metric, mode, scope)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_best_config\u001b[39m(\n\u001b[0;32m    790\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    791\u001b[0m     metric: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    792\u001b[0m     mode: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    793\u001b[0m     scope: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlast\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    794\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Dict]:\n\u001b[0;32m    795\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Retrieve the best config corresponding to the trial.\u001b[39;00m\n\u001b[0;32m    796\u001b[0m \n\u001b[0;32m    797\u001b[0m \u001b[39m    Compares all trials' scores on `metric`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[39m            based on `mode`, and compare trials based on `mode=[min,max]`.\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 818\u001b[0m     best_trial \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_best_trial(metric, mode, scope)\n\u001b[0;32m    819\u001b[0m     \u001b[39mreturn\u001b[39;00m best_trial\u001b[39m.\u001b[39mconfig \u001b[39mif\u001b[39;00m best_trial \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ibele\\anaconda3\\envs\\tuning\\lib\\site-packages\\ray\\tune\\analysis\\experiment_analysis.py:743\u001b[0m, in \u001b[0;36mExperimentAnalysis.get_best_trial\u001b[1;34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[0m\n\u001b[0;32m    740\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials[\u001b[39m0\u001b[39m]\n\u001b[0;32m    742\u001b[0m metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_metric(metric)\n\u001b[1;32m--> 743\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_mode(mode)\n\u001b[0;32m    745\u001b[0m \u001b[39mif\u001b[39;00m scope \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlast\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mavg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlast-5-avg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlast-10-avg\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    746\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    747\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExperimentAnalysis: attempting to get best trial for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    748\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmetric \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m for scope \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m not in [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlast\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mavg\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    753\u001b[0m         )\n\u001b[0;32m    754\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ibele\\anaconda3\\envs\\tuning\\lib\\site-packages\\ray\\tune\\analysis\\experiment_analysis.py:1017\u001b[0m, in \u001b[0;36mExperimentAnalysis._validate_mode\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_mode\u001b[39m(\u001b[39mself\u001b[39m, mode: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m   1016\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mode \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_mode:\n\u001b[1;32m-> 1017\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1018\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mNo `mode` has been passed and  `default_mode` has \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1019\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnot been set. Please specify the `mode` parameter.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1020\u001b[0m         )\n\u001b[0;32m   1021\u001b[0m     \u001b[39mif\u001b[39;00m mode \u001b[39mand\u001b[39;00m mode \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m   1022\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf set, `mode` has to be one of [min, max]\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: No `mode` has been passed and  `default_mode` has not been set. Please specify the `mode` parameter."
     ]
    }
   ],
   "source": [
    "# Access the best hyperparameters\n",
    "best_config = result.get_best_config(metric=\"mean_val_loss\")\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best configuration:\")\n",
    "print(best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_fashion_mnist\",\n  \"trial_id\": \"4609f_00013\",\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059593000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394888c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"_orig_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_orig_experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_local_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_remote_experiment_path\": null,\n  \"config\": {\n    \"epochs\": 20,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 32,\n    \"l1\": 64\n  },\n  \"_Trial__unresolved_config\": {\n    \"epochs\": 20,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 32,\n    \"l1\": 64\n  },\n  \"evaluated_params\": {\n    \"batch_size\": 32,\n    \"epochs\": 20\n  },\n  \"experiment_tag\": \"13_batch_size=32,epochs=20\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"mean_accuracy\": 0.86925,\n    \"mean_val_loss\": 0.3748526468873024,\n    \"time_this_iter_s\": 56.650362730026245,\n    \"done\": true,\n    \"training_iteration\": 20,\n    \"trial_id\": \"4609f_00013\",\n    \"date\": \"2023-08-22_12-50-19\",\n    \"timestamp\": 1692708619,\n    \"time_total_s\": 1087.329656124115,\n    \"pid\": 3050531,\n    \"hostname\": \"dl\",\n    \"node_ip\": \"141.68.100.65\",\n    \"config\": {\n      \"epochs\": 20,\n      \"learning_rate\": 0.001,\n      \"batch_size\": 32,\n      \"l1\": 64\n    },\n    \"time_since_restore\": 1087.329656124115,\n    \"iterations_since_restore\": 20,\n    \"experiment_tag\": \"13_batch_size=32,epochs=20\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1692708619.046748,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.86925,\n      \"min\": 0.6366666666666667,\n      \"avg\": 0.823425,\n      \"last\": 0.86925,\n      \"last-5-avg\": 0.8660666666666665,\n      \"last-10-avg\": 0.8600999999999999\n    },\n    \"mean_val_loss\": {\n      \"max\": 1.2913970858256023,\n      \"min\": 0.3748526468873024,\n      \"avg\": 0.5104194027910629,\n      \"last\": 0.3748526468873024,\n      \"last-5-avg\": 0.3850794354796409,\n      \"last-10-avg\": 0.4011923522253831\n    },\n    \"time_this_iter_s\": {\n      \"max\": 66.91240501403809,\n      \"min\": 45.064295291900635,\n      \"avg\": 54.36648280620575,\n      \"last\": 56.650362730026245,\n      \"last-5-avg\": 61.73858666419983,\n      \"last-10-avg\": 57.528548455238344\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 20,\n      \"min\": 1,\n      \"avg\": 10.5,\n      \"last\": 20,\n      \"last-5-avg\": 18.0,\n      \"last-10-avg\": 15.5\n    },\n    \"time_total_s\": {\n      \"max\": 1087.329656124115,\n      \"min\": 66.91240501403809,\n      \"avg\": 552.3590615868569,\n      \"last\": 1087.329656124115,\n      \"last-5-avg\": 966.6469948768615,\n      \"last-10-avg\": 817.2657312631607\n    },\n    \"time_since_restore\": {\n      \"max\": 1087.329656124115,\n      \"min\": 66.91240501403809,\n      \"avg\": 552.3590615868569,\n      \"last\": 1087.329656124115,\n      \"last-5-avg\": 966.6469948768615,\n      \"last-10-avg\": 817.2657312631607\n    },\n    \"iterations_since_restore\": {\n      \"max\": 20,\n      \"min\": 1,\n      \"avg\": 10.5,\n      \"last\": 20,\n      \"last-5-avg\": 18.0,\n      \"last-10-avg\": 15.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473febb22d0e560419473feb900aec33e1f6473febb22d0e560419473febcccccccccccd473febd0e560418937652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473feb263ab596de8d473feb2fc962fc9630473feb7ef9db22d0e5473feb7b900aec33e2473feb58bf258bf259473febb22d0e560419473feb900aec33e1f6473febb22d0e560419473febcccccccccccd473febd0e560418937652e\"\n      }\n    },\n    \"mean_val_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd92b504a1735ee473fd955c051b4e81b473fd8b56591c54a69473fd805a8f2d0e560473fd7fd95f4cccccd652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdbc790b7b900af473fdb572017ae147b473fda650326f46509473fda32199e978d50473fd9d3d836666666473fd92b504a1735ee473fd955c051b4e81b473fd8b56591c54a69473fd805a8f2d0e560473fd7fd95f4cccccd652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404f0f294c0000004740502c08d100000047404fcaced400000047404ed3693200000047404c533f16000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474049f402220000004740497fe9900000004740490ca8e4000000474049e4da6400000047404ee669be00000047404f0f294c0000004740502c08d100000047404fcaced400000047404ed3693200000047404c533f16000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b104b114b124b134b14652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0b4b0c4b0d4b0e4b0f4b104b114b124b134b14652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a460a96e0000047408c4b8bb100000047408e48389e4000004740901ab798b00000474090fd5191600000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740819f9a98c00000474083379931c00000474084c863c000000047408666b16640000047408855180220000047408a460a96e0000047408c4b8bb100000047408e48389e4000004740901ab798b00000474090fd5191600000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408a460a96e0000047408c4b8bb100000047408e48389e4000004740901ab798b00000474090fd5191600000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740819f9a98c00000474083379931c00000474084c863c000000047408666b16640000047408855180220000047408a460a96e0000047408c4b8bb100000047408e48389e4000004740901ab798b00000474090fd5191600000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b104b114b124b134b14652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0b4b0c4b0d4b0e4b0f4b104b114b124b134b14652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1692707531.696475,\n  \"relative_logdir\": \"train_fashion_mnist_4609f_00013_13_batch_size=32,epochs=20_2023-08-22_12-06-07\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"saving_to\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595fe000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d1020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944affffffff8c0c73746f726167655f6d6f646594681a8c11436865636b706f696e7453746f726167659493944b01859452948c0472616e6b944b008c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f7079948875628c185f636865636b706f696e74735f746f5f636c65616e5f7570948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"_resources\": \"80054e2e\"\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_fashion_mnist\",\n  \"trial_id\": \"4609f_00015\",\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059593000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394888c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"_orig_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_orig_experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_local_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_remote_experiment_path\": null,\n  \"config\": {\n    \"epochs\": 20,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 128,\n    \"l1\": 64\n  },\n  \"_Trial__unresolved_config\": {\n    \"epochs\": 20,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 128,\n    \"l1\": 64\n  },\n  \"evaluated_params\": {\n    \"batch_size\": 128,\n    \"epochs\": 20\n  },\n  \"experiment_tag\": \"15_batch_size=128,epochs=20\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"mean_accuracy\": 0.80475,\n    \"mean_val_loss\": 0.5484613275274317,\n    \"time_this_iter_s\": 19.696027278900146,\n    \"done\": true,\n    \"training_iteration\": 20,\n    \"trial_id\": \"4609f_00015\",\n    \"date\": \"2023-08-22_12-50-12\",\n    \"timestamp\": 1692708612,\n    \"time_total_s\": 401.09473037719727,\n    \"pid\": 3227487,\n    \"hostname\": \"dl\",\n    \"node_ip\": \"141.68.100.65\",\n    \"config\": {\n      \"epochs\": 20,\n      \"learning_rate\": 0.001,\n      \"batch_size\": 128,\n      \"l1\": 64\n    },\n    \"time_since_restore\": 401.09473037719727,\n    \"iterations_since_restore\": 20,\n    \"experiment_tag\": \"15_batch_size=128,epochs=20\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1692708612.4865198,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.80475,\n      \"min\": 0.36041666666666666,\n      \"avg\": 0.7271291666666666,\n      \"last\": 0.80475,\n      \"last-5-avg\": 0.7973833333333333,\n      \"last-10-avg\": 0.7882583333333335\n    },\n    \"mean_val_loss\": {\n      \"max\": 2.208800531448202,\n      \"min\": 0.5484613275274317,\n      \"avg\": 0.8773720840665886,\n      \"last\": 0.5484613275274317,\n      \"last-5-avg\": 0.5624625008791051,\n      \"last-10-avg\": 0.5853390866771657\n    },\n    \"time_this_iter_s\": {\n      \"max\": 26.956286191940308,\n      \"min\": 18.38601851463318,\n      \"avg\": 20.054736518859862,\n      \"last\": 19.696027278900146,\n      \"last-5-avg\": 19.963600063323973,\n      \"last-10-avg\": 19.86238980293274\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 20,\n      \"min\": 1,\n      \"avg\": 10.5,\n      \"last\": 20,\n      \"last-5-avg\": 18.0,\n      \"last-10-avg\": 15.5\n    },\n    \"time_total_s\": {\n      \"max\": 401.09473037719727,\n      \"min\": 26.956286191940308,\n      \"avg\": 213.08789948225024,\n      \"last\": 401.09473037719727,\n      \"last-5-avg\": 361.05054993629454,\n      \"last-10-avg\": 311.62285709381104\n    },\n    \"time_since_restore\": {\n      \"max\": 401.09473037719727,\n      \"min\": 26.956286191940308,\n      \"avg\": 213.08789948225024,\n      \"last\": 401.09473037719727,\n      \"last-5-avg\": 361.05054993629454,\n      \"last-10-avg\": 311.62285709381104\n    },\n    \"iterations_since_restore\": {\n      \"max\": 20,\n      \"min\": 1,\n      \"avg\": 10.5,\n      \"last\": 20,\n      \"last-5-avg\": 18.0,\n      \"last-10-avg\": 15.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe95c28f5c28f5c473fe9810624dd2f1b473fe98057619f0fb4473fe976c8b4395810473fe9c083126e978d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe8a11bfd44f308473fe8d4fdf3b645a2473fe8f671529a485d473fe906d3a06d3a07473fe935ee402bb0d0473fe95c28f5c28f5c473fe9810624dd2f1b473fe98057619f0fb4473fe976c8b4395810473fe9c083126e978d652e\"\n      }\n    },\n    \"mean_val_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe296b07415c988473fe2226d7d46cefb473fe1f3d7a95c9883473fe1c4826b3bea36473fe18cfec51b3bea652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe443eac1057262473fe3c9863b931057473fe36ad32b931057473fe31075d751b3bf473fe2c7c992620ae5473fe296b07415c988473fe2226d7d46cefb473fe1f3d7a95c9883473fe1c4826b3bea36473fe18cfec51b3bea652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474032b3db50000000474034f5fc80000000474034e650440000004740338f118c000000474033b22ed8000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740343e3a200000004740341dd498000000474033ab86d00000004740332761dc0000004740339f57ec000000474032b3db50000000474034f5fc80000000474034e650440000004740338f118c000000474033b22ed8000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b104b114b124b134b14652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0b4b0c4b0d4b0e4b0f4b104b114b124b134b14652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474073ffab318000004740754f0af98000004740769d6ffdc00000474077d66116800000474079118404000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406bd6d85300000047406e5a92e60000004740706801e00000004740719a77fdc00000474072d46d7c800000474073ffab318000004740754f0af98000004740769d6ffdc00000474077d66116800000474079118404000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474073ffab318000004740754f0af98000004740769d6ffdc00000474077d66116800000474079118404000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406bd6d85300000047406e5a92e60000004740706801e00000004740719a77fdc00000474072d46d7c800000474073ffab318000004740754f0af98000004740769d6ffdc00000474077d66116800000474079118404000000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b104b114b124b134b14652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0b4b0c4b0d4b0e4b0f4b104b114b124b134b14652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1692708211.3634253,\n  \"relative_logdir\": \"train_fashion_mnist_4609f_00015_15_batch_size=128,epochs=20_2023-08-22_12-06-07\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"saving_to\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595fe000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d1020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944affffffff8c0c73746f726167655f6d6f646594681a8c11436865636b706f696e7453746f726167659493944b01859452948c0472616e6b944b008c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f7079948875628c185f636865636b706f696e74735f746f5f636c65616e5f7570948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"_resources\": \"80054e2e\"\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_fashion_mnist\",\n  \"trial_id\": \"4609f_00004\",\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059593000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394888c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"_orig_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_orig_experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_local_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_remote_experiment_path\": null,\n  \"config\": {\n    \"epochs\": 10,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 16,\n    \"l1\": 64\n  },\n  \"_Trial__unresolved_config\": {\n    \"epochs\": 10,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 16,\n    \"l1\": 64\n  },\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"epochs\": 10\n  },\n  \"experiment_tag\": \"4_batch_size=16,epochs=10\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"mean_accuracy\": 0.8611666666666666,\n    \"mean_val_loss\": 0.392781325434645,\n    \"time_this_iter_s\": 143.02029752731323,\n    \"done\": true,\n    \"training_iteration\": 10,\n    \"trial_id\": \"4609f_00004\",\n    \"date\": \"2023-08-22_12-30-22\",\n    \"timestamp\": 1692707422,\n    \"time_total_s\": 1273.4488384723663,\n    \"pid\": 2695776,\n    \"hostname\": \"dl\",\n    \"node_ip\": \"141.68.100.65\",\n    \"config\": {\n      \"epochs\": 10,\n      \"learning_rate\": 0.001,\n      \"batch_size\": 16,\n      \"l1\": 64\n    },\n    \"time_since_restore\": 1273.4488384723663,\n    \"iterations_since_restore\": 10,\n    \"experiment_tag\": \"4_batch_size=16,epochs=10\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1692707422.928296,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8611666666666666,\n      \"min\": 0.7206666666666667,\n      \"avg\": 0.8182333333333333,\n      \"last\": 0.8611666666666666,\n      \"last-5-avg\": 0.8472,\n      \"last-10-avg\": 0.8182333333333333\n    },\n    \"mean_val_loss\": {\n      \"max\": 0.7617152489423752,\n      \"min\": 0.392781325434645,\n      \"avg\": 0.49994882390449435,\n      \"last\": 0.392781325434645,\n      \"last-5-avg\": 0.4271265147825082,\n      \"last-10-avg\": 0.4999488239044944\n    },\n    \"time_this_iter_s\": {\n      \"max\": 149.97318172454834,\n      \"min\": 92.56459474563599,\n      \"avg\": 127.34488384723664,\n      \"last\": 143.02029752731323,\n      \"last-5-avg\": 142.26524634361266,\n      \"last-10-avg\": 127.34488384723663\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 10,\n      \"min\": 1,\n      \"avg\": 5.5,\n      \"last\": 10,\n      \"last-5-avg\": 8.0,\n      \"last-10-avg\": 5.5\n    },\n    \"time_total_s\": {\n      \"max\": 1273.4488384723663,\n      \"min\": 94.49432730674744,\n      \"avg\": 652.8762003183365,\n      \"last\": 1273.4488384723663,\n      \"last-5-avg\": 990.8068101406097,\n      \"last-10-avg\": 652.8762003183365\n    },\n    \"time_since_restore\": {\n      \"max\": 1273.4488384723663,\n      \"min\": 94.49432730674744,\n      \"avg\": 652.8762003183365,\n      \"last\": 1273.4488384723663,\n      \"last-5-avg\": 990.8068101406097,\n      \"last-10-avg\": 652.8762003183365\n    },\n    \"iterations_since_restore\": {\n      \"max\": 10,\n      \"min\": 1,\n      \"avg\": 5.5,\n      \"last\": 10,\n      \"last-5-avg\": 8.0,\n      \"last-10-avg\": 5.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473feabf258bf258bf473fead5acb6f46509473feb237fa89e60f0473feb46508dfea27a473feb8ead65b7a328652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe70fb38a94d243473fe8ee402bb0cf88473fe9a485cd7b900b473fea2b020c49ba5e473fea7ae147ae147b473feabf258bf258bf473fead5acb6f46509473feb237fa89e60f0473feb46508dfea27a473feb8ead65b7a328652e\"\n      }\n    },\n    \"mean_val_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdd70d841242e6c473fdcdb6c6908dfea473fdadf7ee657619f473fda5f1c65fbe76d473fd9235448ce2a53652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe85ff8a8624dd3473fe3078e94bc6a7f473fe131efe8dbd194473fdfdd47cb08dfea473fde39332e8f5c29473fdd70d841242e6c473fdcdb6c6908dfea473fdadf7ee657619f473fda5f1c65fbe76d473fd9235448ce2a53652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474062bf244e00000047406102155d800000474061b7a69f80000047406190e9eb800000474061e0a647000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740579fa30f00000047405724225200000047405d89fd2f00000047405e27d06c0000004740610922e7000000474062bf244e00000047406102155d800000474061b7a69f80000047406190e9eb800000474061e0a647000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b0a652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408640c42cc0000047408a81498420000047408eef332c000000474091a9b6d3700000474093e5cb9c500000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740579fa30f00000047406761e2b08000004740731370a400000047407a9d64bf00000047408190fb1940000047408640c42cc0000047408a81498420000047408eef332c000000474091a9b6d3700000474093e5cb9c500000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408640c42cc0000047408a81498420000047408eef332c000000474091a9b6d3700000474093e5cb9c500000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740579fa30f00000047406761e2b08000004740731370a400000047407a9d64bf00000047408190fb1940000047408640c42cc0000047408a81498420000047408eef332c000000474091a9b6d3700000474093e5cb9c500000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b0a652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1692706149.4587924,\n  \"relative_logdir\": \"train_fashion_mnist_4609f_00004_4_batch_size=16,epochs=10_2023-08-22_12-06-07\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"saving_to\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595fe000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d1020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944affffffff8c0c73746f726167655f6d6f646594681a8c11436865636b706f696e7453746f726167659493944b01859452948c0472616e6b944b008c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f7079948875628c185f636865636b706f696e74735f746f5f636c65616e5f7570948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"_resources\": \"80054e2e\"\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_fashion_mnist\",\n  \"trial_id\": \"4609f_00001\",\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059593000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394888c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"_orig_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_orig_experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_local_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_remote_experiment_path\": null,\n  \"config\": {\n    \"epochs\": 5,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 32,\n    \"l1\": 64\n  },\n  \"_Trial__unresolved_config\": {\n    \"epochs\": 5,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 32,\n    \"l1\": 64\n  },\n  \"evaluated_params\": {\n    \"batch_size\": 32,\n    \"epochs\": 5\n  },\n  \"experiment_tag\": \"1_batch_size=32,epochs=5\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"mean_accuracy\": 0.8010833333333334,\n    \"mean_val_loss\": 0.5606536434094112,\n    \"time_this_iter_s\": 53.30585718154907,\n    \"done\": true,\n    \"training_iteration\": 5,\n    \"trial_id\": \"4609f_00001\",\n    \"date\": \"2023-08-22_12-11-56\",\n    \"timestamp\": 1692706316,\n    \"time_total_s\": 305.22740030288696,\n    \"pid\": 2671672,\n    \"hostname\": \"dl\",\n    \"node_ip\": \"141.68.100.65\",\n    \"config\": {\n      \"epochs\": 5,\n      \"learning_rate\": 0.001,\n      \"batch_size\": 32,\n      \"l1\": 64\n    },\n    \"time_since_restore\": 305.22740030288696,\n    \"iterations_since_restore\": 5,\n    \"experiment_tag\": \"1_batch_size=32,epochs=5\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1692706316.2407331,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8010833333333334,\n      \"min\": 0.6396666666666667,\n      \"avg\": 0.7450166666666667,\n      \"last\": 0.8010833333333334,\n      \"last-5-avg\": 0.7450166666666667,\n      \"last-10-avg\": 0.7450166666666667\n    },\n    \"mean_val_loss\": {\n      \"max\": 1.234256614526113,\n      \"min\": 0.5606536434094112,\n      \"avg\": 0.7573369442701341,\n      \"last\": 0.5606536434094112,\n      \"last-5-avg\": 0.757336944270134,\n      \"last-10-avg\": 0.757336944270134\n    },\n    \"time_this_iter_s\": {\n      \"max\": 80.69536757469177,\n      \"min\": 51.510069608688354,\n      \"avg\": 61.0454800605774,\n      \"last\": 53.30585718154907,\n      \"last-5-avg\": 61.04548006057739,\n      \"last-10-avg\": 61.04548006057739\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"time_total_s\": {\n      \"max\": 305.22740030288696,\n      \"min\": 80.69536757469177,\n      \"avg\": 195.4758984565735,\n      \"last\": 305.22740030288696,\n      \"last-5-avg\": 195.47589845657347,\n      \"last-10-avg\": 195.47589845657347\n    },\n    \"time_since_restore\": {\n      \"max\": 305.22740030288696,\n      \"min\": 80.69536757469177,\n      \"avg\": 195.4758984565735,\n      \"last\": 305.22740030288696,\n      \"last-5-avg\": 195.47589845657347,\n      \"last-10-avg\": 195.47589845657347\n    },\n    \"iterations_since_restore\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe478263ab596df473fe7cc1e098ead66473fe86c8b43958106473fe8e098ead65b7a473fe9a27983c131d6652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe478263ab596df473fe7cc1e098ead66473fe86c8b43958106473fe8e098ead65b7a473fe9a27983c131d6652e\"\n      }\n    },\n    \"mean_val_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff3bf83dd242e6c473fe7ac986189374c473fe4b77d3f9db22d473fe358882b851eb8473fe1f0dfe8da740e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff3bf83dd242e6c473fe7ac986189374c473fe4b77d3f9db22d473fe358882b851eb8473fe1f0dfe8da740e652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740542c80e700000047404fa899a0000000474049c149f600000047404c330fbc00000047404aa72654000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740542c80e700000047404fa899a0000000474049c149f600000047404c330fbc00000047404aa72654000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740542c80e70000004740620066db80000047406870b95900000047406f7d7d4800000047407313a36e800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740542c80e70000004740620066db80000047406870b95900000047406f7d7d4800000047407313a36e800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740542c80e70000004740620066db80000047406870b95900000047406f7d7d4800000047407313a36e800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740542c80e70000004740620066db80000047406870b95900000047406f7d7d4800000047407313a36e800000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1692706010.990901,\n  \"relative_logdir\": \"train_fashion_mnist_4609f_00001_1_batch_size=32,epochs=5_2023-08-22_12-06-06\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"saving_to\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595fe000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d1020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944affffffff8c0c73746f726167655f6d6f646594681a8c11436865636b706f696e7453746f726167659493944b01859452948c0472616e6b944b008c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f7079948875628c185f636865636b706f696e74735f746f5f636c65616e5f7570948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"_resources\": \"80054e2e\"\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_fashion_mnist\",\n  \"trial_id\": \"4609f_00010\",\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059593000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394888c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"_orig_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_orig_experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_local_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_remote_experiment_path\": null,\n  \"config\": {\n    \"epochs\": 15,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 64,\n    \"l1\": 64\n  },\n  \"_Trial__unresolved_config\": {\n    \"epochs\": 15,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 64,\n    \"l1\": 64\n  },\n  \"evaluated_params\": {\n    \"batch_size\": 64,\n    \"epochs\": 15\n  },\n  \"experiment_tag\": \"10_batch_size=64,epochs=15\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"mean_accuracy\": 0.8241666666666667,\n    \"mean_val_loss\": 0.49318996388861475,\n    \"time_this_iter_s\": 27.516921520233154,\n    \"done\": true,\n    \"training_iteration\": 15,\n    \"trial_id\": \"4609f_00010\",\n    \"date\": \"2023-08-22_12-27-54\",\n    \"timestamp\": 1692707274,\n    \"time_total_s\": 403.6167240142822,\n    \"pid\": 2882312,\n    \"hostname\": \"dl\",\n    \"node_ip\": \"141.68.100.65\",\n    \"config\": {\n      \"epochs\": 15,\n      \"learning_rate\": 0.001,\n      \"batch_size\": 64,\n      \"l1\": 64\n    },\n    \"time_since_restore\": 403.6167240142822,\n    \"iterations_since_restore\": 15,\n    \"experiment_tag\": \"10_batch_size=64,epochs=15\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1692707274.6863787,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8241666666666667,\n      \"min\": 0.45608333333333334,\n      \"avg\": 0.7576888888888889,\n      \"last\": 0.8241666666666667,\n      \"last-5-avg\": 0.8145333333333333,\n      \"last-10-avg\": 0.8001166666666666\n    },\n    \"mean_val_loss\": {\n      \"max\": 2.074315717879762,\n      \"min\": 0.49318996388861475,\n      \"avg\": 0.7476781654970865,\n      \"last\": 0.49318996388861475,\n      \"last-5-avg\": 0.5145684522834231,\n      \"last-10-avg\": 0.5509713471094344\n    },\n    \"time_this_iter_s\": {\n      \"max\": 34.0912070274353,\n      \"min\": 24.774762392044067,\n      \"avg\": 26.90778160095215,\n      \"last\": 27.516921520233154,\n      \"last-5-avg\": 26.411495685577393,\n      \"last-10-avg\": 26.619074201583864\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 403.6167240142822,\n      \"min\": 34.0912070274353,\n      \"avg\": 217.43158372243246,\n      \"last\": 403.6167240142822,\n      \"last-5-avg\": 350.1796163082123,\n      \"last-10-avg\": 283.43247640132904\n    },\n    \"time_since_restore\": {\n      \"max\": 403.6167240142822,\n      \"min\": 34.0912070274353,\n      \"avg\": 217.43158372243246,\n      \"last\": 403.6167240142822,\n      \"last-5-avg\": 350.1796163082123,\n      \"last-10-avg\": 283.43247640132904\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe9b22d0e560419473fea04189374bc6a473fea1f671529a486473fea1e098ead65b8473fea5f92c5f92c60652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe8b0cf87d9c54a473fe9098ead65b7a3473fe9555555555555473fe9735ee402bb0d473fe9333333333333473fe9b22d0e560419473fea04189374bc6a473fea1f671529a486473fea1e098ead65b8473fea5f92c5f92c60652e\"\n      }\n    },\n    \"mean_val_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe14457cf677d47473fe0a2bbacd9df52473fe05cb62f931057473fe048b94dc9882c473fdf906ca3677d47652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe436a718c415ca473fe3344d7a3677d4473fe29ecbf3ea3678473fe20222a37d46cf473fe1eef62a620ae5473fe14457cf677d47473fe0a2bbacd9df52473fe05cb62f931057473fe048b94dc9882c473fdf906ca3677d47652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474039cf91e000000047403adbe96c0000004740395a71c400000047403a8474e000000047403b8454f8000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403b3d10c8000000474038fd5c7000000047403a6a01fc000000474039697f5000000047403e142f0c000000474039cf91e000000047403adbe96c0000004740395a71c400000047403a8474e000000047403b8454f8000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407295ebc980000047407443aa60400000474075d9517c8000004740778198ca80000047407939de1a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740649543be000000474067b4ef4c00000047406b022f8b80000047406e2f5f75800000474070f8f2ab80000047407295ebc980000047407443aa60400000474075d9517c8000004740778198ca80000047407939de1a000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407295ebc980000047407443aa60400000474075d9517c8000004740778198ca80000047407939de1a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740649543be000000474067b4ef4c00000047406b022f8b80000047406e2f5f75800000474070f8f2ab80000047407295ebc980000047407443aa60400000474075d9517c8000004740778198ca80000047407939de1a000000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1692706871.0479434,\n  \"relative_logdir\": \"train_fashion_mnist_4609f_00010_10_batch_size=64,epochs=15_2023-08-22_12-06-07\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"saving_to\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595fe000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d1020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944affffffff8c0c73746f726167655f6d6f646594681a8c11436865636b706f696e7453746f726167659493944b01859452948c0472616e6b944b008c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f7079948875628c185f636865636b706f696e74735f746f5f636c65616e5f7570948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"_resources\": \"80054e2e\"\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_fashion_mnist\",\n  \"trial_id\": \"4609f_00014\",\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059593000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394888c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"_orig_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_orig_experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_local_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_remote_experiment_path\": null,\n  \"config\": {\n    \"epochs\": 20,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 64,\n    \"l1\": 64\n  },\n  \"_Trial__unresolved_config\": {\n    \"epochs\": 20,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 64,\n    \"l1\": 64\n  },\n  \"evaluated_params\": {\n    \"batch_size\": 64,\n    \"epochs\": 20\n  },\n  \"experiment_tag\": \"14_batch_size=64,epochs=20\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"mean_accuracy\": 0.83325,\n    \"mean_val_loss\": 0.4722811340334568,\n    \"time_this_iter_s\": 27.343737602233887,\n    \"done\": true,\n    \"training_iteration\": 20,\n    \"trial_id\": \"4609f_00014\",\n    \"date\": \"2023-08-22_12-43-01\",\n    \"timestamp\": 1692708181,\n    \"time_total_s\": 541.618026971817,\n    \"pid\": 3072864,\n    \"hostname\": \"dl\",\n    \"node_ip\": \"141.68.100.65\",\n    \"config\": {\n      \"epochs\": 20,\n      \"learning_rate\": 0.001,\n      \"batch_size\": 64,\n      \"l1\": 64\n    },\n    \"time_since_restore\": 541.618026971817,\n    \"iterations_since_restore\": 20,\n    \"experiment_tag\": \"14_batch_size=64,epochs=20\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1692708181.884541,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.83325,\n      \"min\": 0.5668333333333333,\n      \"avg\": 0.7755416666666667,\n      \"last\": 0.83325,\n      \"last-5-avg\": 0.8241666666666667,\n      \"last-10-avg\": 0.8146916666666666\n    },\n    \"mean_val_loss\": {\n      \"max\": 2.078181917363025,\n      \"min\": 0.4722811340334568,\n      \"avg\": 0.6888732498075736,\n      \"last\": 0.4722811340334568,\n      \"last-5-avg\": 0.49142341515485277,\n      \"last-10-avg\": 0.5141835484415928\n    },\n    \"time_this_iter_s\": {\n      \"max\": 33.226165771484375,\n      \"min\": 25.014399766921997,\n      \"avg\": 27.080901348590853,\n      \"last\": 27.343737602233887,\n      \"last-5-avg\": 26.682348203659057,\n      \"last-10-avg\": 26.76471016407013\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 20,\n      \"min\": 1,\n      \"avg\": 10.5,\n      \"last\": 20,\n      \"last-5-avg\": 18.0,\n      \"last-10-avg\": 15.5\n    },\n    \"time_total_s\": {\n      \"max\": 541.618026971817,\n      \"min\": 33.226165771484375,\n      \"avg\": 287.60330193042756,\n      \"last\": 541.618026971817,\n      \"last-5-avg\": 487.89794921875,\n      \"last-10-avg\": 421.1450732946396\n    },\n    \"time_since_restore\": {\n      \"max\": 541.618026971817,\n      \"min\": 33.226165771484375,\n      \"avg\": 287.60330193042756,\n      \"last\": 541.618026971817,\n      \"last-5-avg\": 487.89794921875,\n      \"last-10-avg\": 421.1450732946396\n    },\n    \"iterations_since_restore\": {\n      \"max\": 20,\n      \"min\": 1,\n      \"avg\": 10.5,\n      \"last\": 20,\n      \"last-5-avg\": 18.0,\n      \"last-10-avg\": 15.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fea28f5c28f5c29473fea374bc6a7ef9e473fea6508dfea2798473fea6e978d4fdf3b473feaa9fbe76c8b44652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe983126e978d50473fe999999999999a473fe9cc1e098ead66473fe9e5604189374c473fea078263ab596e473fea28f5c28f5c29473fea374bc6a7ef9e473fea6508dfea2798473fea6e978d4fdf3b473feaa9fbe76c8b44652e\"\n      }\n    },\n    \"mean_val_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe05780a9f51b3c473fdff3aae1df51b4473fdf593ddcefa8da473fdf0ba341b3bea3473fde39daa64c415d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe1bb82349882b9473fe190bdd882b931473fe121e982e4c416473fe0ed6543bea367473fe08da7c0c415ca473fe05780a9f51b3c473fdff3aae1df51b4473fdf593ddcefa8da473fdf0ba341b3bea3473fde39daa64c415d652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474039b451f400000047403c6cef1000000047403903afb400000047403aec77f400000047403b57ff30000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403b39807400000047403af0cbe000000047403a0824c400000047403a164adc00000047403bf384a4000000474039b451f400000047403c6cef1000000047403903afb400000047403aec77f400000047403b57ff30000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b104b114b124b134b14652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0b4b0c4b0d4b0e4b0f4b104b114b124b134b14652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407b1e9211c0000047407ce56102c0000047407e759bfe0000004740801231bea00000474080ecf1b8200000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474072d320f0400000474074822dae40000047407622affa800000474077c414a8400000474079834cf280000047407b1e9211c0000047407ce56102c0000047407e759bfe0000004740801231bea00000474080ecf1b8200000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407b1e9211c0000047407ce56102c0000047407e759bfe0000004740801231bea00000474080ecf1b8200000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474072d320f0400000474074822dae40000047407622affa800000474077c414a8400000474079834cf280000047407b1e9211c0000047407ce56102c0000047407e759bfe0000004740801231bea00000474080ecf1b8200000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b104b114b124b134b14652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0b4b0c4b0d4b0e4b0f4b104b114b124b134b14652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1692707640.2472003,\n  \"relative_logdir\": \"train_fashion_mnist_4609f_00014_14_batch_size=64,epochs=20_2023-08-22_12-06-07\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"saving_to\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595fe000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d1020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944affffffff8c0c73746f726167655f6d6f646594681a8c11436865636b706f696e7453746f726167659493944b01859452948c0472616e6b944b008c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f7079948875628c185f636865636b706f696e74735f746f5f636c65616e5f7570948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"_resources\": \"80054e2e\"\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_fashion_mnist\",\n  \"trial_id\": \"4609f_00011\",\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059593000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394888c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"_orig_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_orig_experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_local_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_remote_experiment_path\": null,\n  \"config\": {\n    \"epochs\": 15,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 128,\n    \"l1\": 64\n  },\n  \"_Trial__unresolved_config\": {\n    \"epochs\": 15,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 128,\n    \"l1\": 64\n  },\n  \"evaluated_params\": {\n    \"batch_size\": 128,\n    \"epochs\": 15\n  },\n  \"experiment_tag\": \"11_batch_size=128,epochs=15\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"mean_accuracy\": 0.7808333333333334,\n    \"mean_val_loss\": 0.5976170402892093,\n    \"time_this_iter_s\": 20.83316683769226,\n    \"done\": true,\n    \"training_iteration\": 15,\n    \"trial_id\": \"4609f_00011\",\n    \"date\": \"2023-08-22_12-33-32\",\n    \"timestamp\": 1692707612,\n    \"time_total_s\": 308.9803216457367,\n    \"pid\": 2999221,\n    \"hostname\": \"dl\",\n    \"node_ip\": \"141.68.100.65\",\n    \"config\": {\n      \"epochs\": 15,\n      \"learning_rate\": 0.001,\n      \"batch_size\": 128,\n      \"l1\": 64\n    },\n    \"time_since_restore\": 308.9803216457367,\n    \"iterations_since_restore\": 15,\n    \"experiment_tag\": \"11_batch_size=128,epochs=15\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1692707612.9873571,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.7808333333333334,\n      \"min\": 0.2826666666666667,\n      \"avg\": 0.6792388888888888,\n      \"last\": 0.7808333333333334,\n      \"last-5-avg\": 0.7699166666666667,\n      \"last-10-avg\": 0.7502166666666668\n    },\n    \"mean_val_loss\": {\n      \"max\": 2.239644651717328,\n      \"min\": 0.5976170402892093,\n      \"avg\": 1.0931095600762262,\n      \"last\": 0.5976170402892093,\n      \"last-5-avg\": 0.6314305601601905,\n      \"last-10-avg\": 0.7280725319017753\n    },\n    \"time_this_iter_s\": {\n      \"max\": 27.360224962234497,\n      \"min\": 18.246171712875366,\n      \"avg\": 20.59868810971578,\n      \"last\": 20.83316683769226,\n      \"last-5-avg\": 20.45051736831665,\n      \"last-10-avg\": 20.295526695251464\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 308.9803216457367,\n      \"min\": 27.360224962234497,\n      \"avg\": 167.0259786605835,\n      \"last\": 308.9803216457367,\n      \"last-5-avg\": 267.7292088508606,\n      \"last-10-avg\": 217.45464482307435\n    },\n    \"time_since_restore\": {\n      \"max\": 308.9803216457367,\n      \"min\": 27.360224962234497,\n      \"avg\": 167.0259786605835,\n      \"last\": 308.9803216457367,\n      \"last-5-avg\": 267.7292088508606,\n      \"last-10-avg\": 217.45464482307435\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe849ba5e353f7d473fe8756b2dbd1942473fe8a1cac083126f473fe8d242e6bdc805473fe8fc962fc962fd652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe694d242e6bdc8473fe70cf87d9c54a7473fe76de8ca11bfd4473fe7c8057619f0fb473fe80a3d70a3d70a473fe849ba5e353f7d473fe8756b2dbd1942473fe8a1cac083126f473fe8d242e6bdc805473fe8fc962fc962fd652e\"\n      }\n    },\n    \"mean_val_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe576b6b51b3bea473fe4b973182b9310473fe4200bec6cefa9473fe39781d0572621473fe31fadc572620b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0282cfcefa8da473fec1df4a82b9310473fe9711df2620ae5473fe7ab7c8a8d9df5473fe669653b931057473fe576b6b51b3bea473fe4b973182b9310473fe4200bec6cefa9473fe39781d0572621473fe31fadc572620b652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474034fde4a8000000474032e6141c000000474034900430000000474034f76228000000474034d54a6c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740324ef14c000000474038e450080000004740337568dc0000004740323f051c000000474033cc338c000000474034fde4a8000000474032e6141c000000474034900430000000474034f76228000000474034d54a6c000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847406c77062f80000047406ed3c8b3000000474070b2e49c800000474072025abf0000004740734faf65c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405f1556d2000000474062a7356a00000047406515e2858000004740675dc329000000474069d7499a80000047406c77062f80000047406ed3c8b3000000474070b2e49c800000474072025abf0000004740734faf65c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847406c77062f80000047406ed3c8b3000000474070b2e49c800000474072025abf0000004740734faf65c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405f1556d2000000474062a7356a00000047406515e2858000004740675dc329000000474069d7499a80000047406c77062f80000047406ed3c8b3000000474070b2e49c800000474072025abf0000004740734faf65c00000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1692707303.9854562,\n  \"relative_logdir\": \"train_fashion_mnist_4609f_00011_11_batch_size=128,epochs=15_2023-08-22_12-06-07\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"saving_to\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595fe000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d1020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944affffffff8c0c73746f726167655f6d6f646594681a8c11436865636b706f696e7453746f726167659493944b01859452948c0472616e6b944b008c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f7079948875628c185f636865636b706f696e74735f746f5f636c65616e5f7570948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"_resources\": \"80054e2e\"\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_fashion_mnist\",\n  \"trial_id\": \"4609f_00002\",\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059593000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394888c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"_orig_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_orig_experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_local_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_remote_experiment_path\": null,\n  \"config\": {\n    \"epochs\": 5,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 64,\n    \"l1\": 64\n  },\n  \"_Trial__unresolved_config\": {\n    \"epochs\": 5,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 64,\n    \"l1\": 64\n  },\n  \"evaluated_params\": {\n    \"batch_size\": 64,\n    \"epochs\": 5\n  },\n  \"experiment_tag\": \"2_batch_size=64,epochs=5\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"mean_accuracy\": 0.7613333333333333,\n    \"mean_val_loss\": 0.668505829699496,\n    \"time_this_iter_s\": 30.655083179473877,\n    \"done\": true,\n    \"training_iteration\": 5,\n    \"trial_id\": \"4609f_00002\",\n    \"date\": \"2023-08-22_12-09-55\",\n    \"timestamp\": 1692706195,\n    \"time_total_s\": 193.5632359981537,\n    \"pid\": 2671673,\n    \"hostname\": \"dl\",\n    \"node_ip\": \"141.68.100.65\",\n    \"config\": {\n      \"epochs\": 5,\n      \"learning_rate\": 0.001,\n      \"batch_size\": 64,\n      \"l1\": 64\n    },\n    \"time_since_restore\": 193.5632359981537,\n    \"iterations_since_restore\": 5,\n    \"experiment_tag\": \"2_batch_size=64,epochs=5\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1692706195.0708702,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.7613333333333333,\n      \"min\": 0.3268333333333333,\n      \"avg\": 0.6414166666666667,\n      \"last\": 0.7613333333333333,\n      \"last-5-avg\": 0.6414166666666666,\n      \"last-10-avg\": 0.6414166666666666\n    },\n    \"mean_val_loss\": {\n      \"max\": 2.0817359140578735,\n      \"min\": 0.668505829699496,\n      \"avg\": 1.1445689213719772,\n      \"last\": 0.668505829699496,\n      \"last-5-avg\": 1.1445689213719772,\n      \"last-10-avg\": 1.1445689213719772\n    },\n    \"time_this_iter_s\": {\n      \"max\": 45.831871032714844,\n      \"min\": 30.655083179473877,\n      \"avg\": 38.71264719963074,\n      \"last\": 30.655083179473877,\n      \"last-5-avg\": 38.71264719963074,\n      \"last-10-avg\": 38.71264719963074\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"time_total_s\": {\n      \"max\": 193.5632359981537,\n      \"min\": 45.831871032714844,\n      \"avg\": 122.84383459091187,\n      \"last\": 193.5632359981537,\n      \"last-5-avg\": 122.84383459091187,\n      \"last-10-avg\": 122.84383459091187\n    },\n    \"time_since_restore\": {\n      \"max\": 193.5632359981537,\n      \"min\": 45.831871032714844,\n      \"avg\": 122.84383459091187,\n      \"last\": 193.5632359981537,\n      \"last-5-avg\": 122.84383459091187,\n      \"last-10-avg\": 122.84383459091187\n    },\n    \"iterations_since_restore\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd4ead65b7a3284473fe50da740da740e473fe6d65b7a328470473fe7ea27983c131d473fe85cd7b900aec3652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd4ead65b7a3284473fe50da740da740e473fe6d65b7a328470473fe7ea27983c131d473fe85cd7b900aec3652e\"\n      }\n    },\n    \"mean_val_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000a76528ae4c41473ff5899e6b3bea36473fec81d6623677d4473fe78a7cd172620b473fe564665677d46d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474000a76528ae4c41473ff5899e6b3bea36473fec81d6623677d4473fe78a7cd172620b473fe564665677d46d652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474046ea7ac0000000474043c76efa00000047404491693000000047404230eb7000000047403ea7b388000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474046ea7ac0000000474043c76efa00000047404491693000000047404230eb7000000047403ea7b388000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474046ea7ac000000047405558f4dd00000047405fa1a9750000004740645d0f96800000474068320607800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474046ea7ac000000047405558f4dd00000047405fa1a9750000004740645d0f96800000474068320607800000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474046ea7ac000000047405558f4dd00000047405fa1a9750000004740645d0f96800000474068320607800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474046ea7ac000000047405558f4dd00000047405fa1a9750000004740645d0f96800000474068320607800000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1692706001.485639,\n  \"relative_logdir\": \"train_fashion_mnist_4609f_00002_2_batch_size=64,epochs=5_2023-08-22_12-06-06\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"saving_to\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595fe000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d1020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944affffffff8c0c73746f726167655f6d6f646594681a8c11436865636b706f696e7453746f726167659493944b01859452948c0472616e6b944b008c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f7079948875628c185f636865636b706f696e74735f746f5f636c65616e5f7570948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"_resources\": \"80054e2e\"\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_fashion_mnist\",\n  \"trial_id\": \"4609f_00003\",\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059593000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394888c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"_orig_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_orig_experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_local_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_remote_experiment_path\": null,\n  \"config\": {\n    \"epochs\": 5,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 128,\n    \"l1\": 64\n  },\n  \"_Trial__unresolved_config\": {\n    \"epochs\": 5,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 128,\n    \"l1\": 64\n  },\n  \"evaluated_params\": {\n    \"batch_size\": 128,\n    \"epochs\": 5\n  },\n  \"experiment_tag\": \"3_batch_size=128,epochs=5\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"mean_accuracy\": 0.6736666666666666,\n    \"mean_val_loss\": 1.1225244453612795,\n    \"time_this_iter_s\": 24.873910427093506,\n    \"done\": true,\n    \"training_iteration\": 5,\n    \"trial_id\": \"4609f_00003\",\n    \"date\": \"2023-08-22_12-08-49\",\n    \"timestamp\": 1692706129,\n    \"time_total_s\": 129.13787460327148,\n    \"pid\": 2671674,\n    \"hostname\": \"dl\",\n    \"node_ip\": \"141.68.100.65\",\n    \"config\": {\n      \"epochs\": 5,\n      \"learning_rate\": 0.001,\n      \"batch_size\": 128,\n      \"l1\": 64\n    },\n    \"time_since_restore\": 129.13787460327148,\n    \"iterations_since_restore\": 5,\n    \"experiment_tag\": \"3_batch_size=128,epochs=5\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1692706129.307676,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.6736666666666666,\n      \"min\": 0.32558333333333334,\n      \"avg\": 0.54015,\n      \"last\": 0.6736666666666666,\n      \"last-5-avg\": 0.54015,\n      \"last-10-avg\": 0.54015\n    },\n    \"mean_val_loss\": {\n      \"max\": 2.238663379182207,\n      \"min\": 1.1225244453612795,\n      \"avg\": 1.767745416722399,\n      \"last\": 1.1225244453612795,\n      \"last-5-avg\": 1.7677454167223992,\n      \"last-10-avg\": 1.7677454167223992\n    },\n    \"time_this_iter_s\": {\n      \"max\": 28.571040153503418,\n      \"min\": 23.409172534942627,\n      \"avg\": 25.8275749206543,\n      \"last\": 24.873910427093506,\n      \"last-5-avg\": 25.827574920654296,\n      \"last-10-avg\": 25.827574920654296\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"time_total_s\": {\n      \"max\": 129.13787460327148,\n      \"min\": 28.571040153503418,\n      \"avg\": 78.24266233444214,\n      \"last\": 129.13787460327148,\n      \"last-5-avg\": 78.24266233444214,\n      \"last-10-avg\": 78.24266233444214\n    },\n    \"time_since_restore\": {\n      \"max\": 129.13787460327148,\n      \"min\": 28.571040153503418,\n      \"avg\": 78.24266233444214,\n      \"last\": 129.13787460327148,\n      \"last-5-avg\": 78.24266233444214,\n      \"last-10-avg\": 78.24266233444214\n    },\n    \"iterations_since_restore\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd4d65b7a328470473fdf258bf258bf26473fe2bb0cf87d9c55473fe424dd2f1a9fbe473fe58ead65b7a328652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd4d65b7a328470473fdf258bf258bf26473fe2bb0cf87d9c55473fe424dd2f1a9fbe473fe58ead65b7a328652e\"\n      }\n    },\n    \"mean_val_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474001e8c85882b931474001022f772620ae473ffe2ece98d9df52473ff770d2ad9df51b473ff1f5dc315c9883652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474001e8c85882b931474001022f772620ae473ffe2ece98d9df52473ff770d2ad9df51b473ff1f5dc315c9883652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c922fb000000047403858370c00000047403768bf8800000047403bf06ce4000000474038dfb898000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403c922fb000000047403858370c00000047403768bf8800000047403bf06ce4000000474038dfb898000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c922fb000000047404a75335e00000047405314c99100000047405a10e4ca000000474060246978000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403c922fb000000047404a75335e00000047405314c99100000047405a10e4ca000000474060246978000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c922fb000000047404a75335e00000047405314c99100000047405a10e4ca000000474060246978000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403c922fb000000047404a75335e00000047405314c99100000047405a10e4ca000000474060246978000000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1692706000.1407132,\n  \"relative_logdir\": \"train_fashion_mnist_4609f_00003_3_batch_size=128,epochs=5_2023-08-22_12-06-06\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"saving_to\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595fe000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d1020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944affffffff8c0c73746f726167655f6d6f646594681a8c11436865636b706f696e7453746f726167659493944b01859452948c0472616e6b944b008c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f7079948875628c185f636865636b706f696e74735f746f5f636c65616e5f7570948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"_resources\": \"80054e2e\"\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_fashion_mnist\",\n  \"trial_id\": \"4609f_00000\",\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059593000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394888c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"_orig_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_orig_experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_local_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_remote_experiment_path\": null,\n  \"config\": {\n    \"epochs\": 5,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 16,\n    \"l1\": 64\n  },\n  \"_Trial__unresolved_config\": {\n    \"epochs\": 5,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 16,\n    \"l1\": 64\n  },\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"epochs\": 5\n  },\n  \"experiment_tag\": \"0_batch_size=16,epochs=5\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"mean_accuracy\": 0.83475,\n    \"mean_val_loss\": 0.46074706014990807,\n    \"time_this_iter_s\": 134.92984580993652,\n    \"done\": true,\n    \"training_iteration\": 5,\n    \"trial_id\": \"4609f_00000\",\n    \"date\": \"2023-08-22_12-17-10\",\n    \"timestamp\": 1692706630,\n    \"time_total_s\": 615.8827970027924,\n    \"pid\": 2671671,\n    \"hostname\": \"dl\",\n    \"node_ip\": \"141.68.100.65\",\n    \"config\": {\n      \"epochs\": 5,\n      \"learning_rate\": 0.001,\n      \"batch_size\": 16,\n      \"l1\": 64\n    },\n    \"time_since_restore\": 615.8827970027924,\n    \"iterations_since_restore\": 5,\n    \"experiment_tag\": \"0_batch_size=16,epochs=5\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1692706630.2078922,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.83475,\n      \"min\": 0.74325,\n      \"avg\": 0.7984833333333334,\n      \"last\": 0.83475,\n      \"last-5-avg\": 0.7984833333333333,\n      \"last-10-avg\": 0.7984833333333333\n    },\n    \"mean_val_loss\": {\n      \"max\": 0.7334720042745272,\n      \"min\": 0.46074706014990807,\n      \"avg\": 0.5628211305836837,\n      \"last\": 0.46074706014990807,\n      \"last-5-avg\": 0.5628211305836837,\n      \"last-10-avg\": 0.5628211305836837\n    },\n    \"time_this_iter_s\": {\n      \"max\": 137.01083135604858,\n      \"min\": 100.92165327072144,\n      \"avg\": 123.17655940055847,\n      \"last\": 134.92984580993652,\n      \"last-5-avg\": 123.17655940055847,\n      \"last-10-avg\": 123.17655940055847\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"time_total_s\": {\n      \"max\": 615.8827970027924,\n      \"min\": 136.57445764541626,\n      \"avg\": 362.9696873188019,\n      \"last\": 615.8827970027924,\n      \"last-5-avg\": 362.9696873188019,\n      \"last-10-avg\": 362.9696873188019\n    },\n    \"time_since_restore\": {\n      \"max\": 615.8827970027924,\n      \"min\": 136.57445764541626,\n      \"avg\": 362.9696873188019,\n      \"last\": 615.8827970027924,\n      \"last-5-avg\": 362.9696873188019,\n      \"last-10-avg\": 362.9696873188019\n    },\n    \"iterations_since_restore\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe7c8b439581062473fe92bb0cf87d9c5473fe9e353f7ced917473fea33e1f671529a473feab645a1cac083652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe7c8b439581062473fe92bb0cf87d9c5473fe9e353f7ced917473fea33e1f671529a473feab645a1cac083652e\"\n      }\n    },\n    \"mean_val_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe7789a47dc8057473fe2eb83780da741473fe114261a7983c1473fdface5a7258bf2473fdd7ce13cc49ba6652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe7789a47dc8057473fe2eb83780da741473fe114261a7983c1473fdface5a7258bf2473fdd7ce13cc49ba6652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740611261f50000004740593afc5e00000047405a9c8b690000004740612058bb000000474060ddc14c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740611261f50000004740593afc5e00000047405a9c8b690000004740612058bb000000474060ddc14c000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740611261f500000047406dafe0240000004740757f12ec40000047407e0f3f49c000004740833f0ff7e00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740611261f500000047406dafe0240000004740757f12ec40000047407e0f3f49c000004740833f0ff7e00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740611261f500000047406dafe0240000004740757f12ec40000047407e0f3f49c000004740833f0ff7e00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740611261f500000047406dafe0240000004740757f12ec40000047407e0f3f49c000004740833f0ff7e00000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1692706014.2888474,\n  \"relative_logdir\": \"train_fashion_mnist_4609f_00000_0_batch_size=16,epochs=5_2023-08-22_12-06-06\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"saving_to\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595fe000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d1020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944affffffff8c0c73746f726167655f6d6f646594681a8c11436865636b706f696e7453746f726167659493944b01859452948c0472616e6b944b008c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f7079948875628c185f636865636b706f696e74735f746f5f636c65616e5f7570948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"_resources\": \"80054e2e\"\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_fashion_mnist\",\n  \"trial_id\": \"4609f_00007\",\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059593000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394888c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"_orig_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_orig_experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_local_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_remote_experiment_path\": null,\n  \"config\": {\n    \"epochs\": 10,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 128,\n    \"l1\": 64\n  },\n  \"_Trial__unresolved_config\": {\n    \"epochs\": 10,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 128,\n    \"l1\": 64\n  },\n  \"evaluated_params\": {\n    \"batch_size\": 128,\n    \"epochs\": 10\n  },\n  \"experiment_tag\": \"7_batch_size=128,epochs=10\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"mean_accuracy\": 0.76625,\n    \"mean_val_loss\": 0.6617536836482109,\n    \"time_this_iter_s\": 20.797293663024902,\n    \"done\": true,\n    \"training_iteration\": 10,\n    \"trial_id\": \"4609f_00007\",\n    \"date\": \"2023-08-22_12-20-46\",\n    \"timestamp\": 1692706846,\n    \"time_total_s\": 202.85600233078003,\n    \"pid\": 2832475,\n    \"hostname\": \"dl\",\n    \"node_ip\": \"141.68.100.65\",\n    \"config\": {\n      \"epochs\": 10,\n      \"learning_rate\": 0.001,\n      \"batch_size\": 128,\n      \"l1\": 64\n    },\n    \"time_since_restore\": 202.85600233078003,\n    \"iterations_since_restore\": 10,\n    \"experiment_tag\": \"7_batch_size=128,epochs=10\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1692706846.1285317,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.76625,\n      \"min\": 0.34475,\n      \"avg\": 0.6548750000000001,\n      \"last\": 0.76625,\n      \"last-5-avg\": 0.7497333333333333,\n      \"last-10-avg\": 0.654875\n    },\n    \"mean_val_loss\": {\n      \"max\": 2.1808632586864714,\n      \"min\": 0.6617536836482109,\n      \"avg\": 1.1300919838408205,\n      \"last\": 0.6617536836482109,\n      \"last-5-avg\": 0.7248332140293527,\n      \"last-10-avg\": 1.1300919838408205\n    },\n    \"time_this_iter_s\": {\n      \"max\": 25.05885076522827,\n      \"min\": 17.401763439178467,\n      \"avg\": 20.285600233078,\n      \"last\": 20.797293663024902,\n      \"last-5-avg\": 20.70775899887085,\n      \"last-10-avg\": 20.285600233078004\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 10,\n      \"min\": 1,\n      \"avg\": 5.5,\n      \"last\": 10,\n      \"last-5-avg\": 8.0,\n      \"last-10-avg\": 5.5\n    },\n    \"time_total_s\": {\n      \"max\": 202.85600233078003,\n      \"min\": 25.05885076522827,\n      \"avg\": 111.84941556453705,\n      \"last\": 202.85600233078003,\n      \"last-5-avg\": 161.4092167377472,\n      \"last-10-avg\": 111.84941556453705\n    },\n    \"time_since_restore\": {\n      \"max\": 202.85600233078003,\n      \"min\": 25.05885076522827,\n      \"avg\": 111.84941556453705,\n      \"last\": 202.85600233078003,\n      \"last-5-avg\": 161.4092167377472,\n      \"last-10-avg\": 111.84941556453705\n    },\n    \"iterations_since_restore\": {\n      \"max\": 10,\n      \"min\": 1,\n      \"avg\": 5.5,\n      \"last\": 10,\n      \"last-5-avg\": 8.0,\n      \"last-10-avg\": 5.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe74f3078263ab6473fe7da740da740da473fe7fd44f3078264473fe8490b9af72016473fe8851eb851eb85652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd610624dd2f1aa473fdf7b900aec33e2473fe32b020c49ba5e473fe532846ff513cc473fe676c8b4395810473fe74f3078263ab6473fe7da740da740da473fe7fd44f3078264473fe8490b9af72016473fe8851eb851eb85652e\"\n      }\n    },\n    \"mean_val_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fea1689cb3bea36473fe8117abb3bea36473fe6d34e7b931057473fe5d0c20d9df51b473fe52d160fa8d9df652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847400172686fa8d9df473fff00758e4c415d473ff825d12bea3678473ff204009fa8d9df473fed89c712620ae5473fea1689cb3bea36473fe8117abb3bea36473fe6d34e7b931057473fe5d0c20d9df51b473fe52d160fa8d9df652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403363bd90000000474036968c68000000474034d5b2a4000000474033edd66c000000474034cc1b70000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740390f10d8000000474032f396a0000000474032d1cf9000000047403166d9f800000047403315e38000000047403363bd90000000474036968c68000000474034d5b2a4000000474033edd66c000000474034cc1b70000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b0a652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847405dad3c84000000474061a96fcf000000474064442623800000474066c1e0f10000004740695b645f000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740390f10d80000004740460153bc00000047404f6a3b840000004740540ed440000000474058d44d2000000047405dad3c84000000474061a96fcf000000474064442623800000474066c1e0f10000004740695b645f000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847405dad3c84000000474061a96fcf000000474064442623800000474066c1e0f10000004740695b645f000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740390f10d80000004740460153bc00000047404f6a3b840000004740540ed440000000474058d44d2000000047405dad3c84000000474061a96fcf000000474064442623800000474066c1e0f10000004740695b645f000000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b0a652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1692706643.251443,\n  \"relative_logdir\": \"train_fashion_mnist_4609f_00007_7_batch_size=128,epochs=10_2023-08-22_12-06-07\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"saving_to\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595fe000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d1020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944affffffff8c0c73746f726167655f6d6f646594681a8c11436865636b706f696e7453746f726167659493944b01859452948c0472616e6b944b008c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f7079948875628c185f636865636b706f696e74735f746f5f636c65616e5f7570948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"_resources\": \"80054e2e\"\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_fashion_mnist\",\n  \"trial_id\": \"4609f_00009\",\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059593000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394888c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"_orig_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_orig_experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_local_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_remote_experiment_path\": null,\n  \"config\": {\n    \"epochs\": 15,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 32,\n    \"l1\": 64\n  },\n  \"_Trial__unresolved_config\": {\n    \"epochs\": 15,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 32,\n    \"l1\": 64\n  },\n  \"evaluated_params\": {\n    \"batch_size\": 32,\n    \"epochs\": 15\n  },\n  \"experiment_tag\": \"9_batch_size=32,epochs=15\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"mean_accuracy\": 0.8526666666666667,\n    \"mean_val_loss\": 0.4060302222569784,\n    \"time_this_iter_s\": 62.338561058044434,\n    \"done\": true,\n    \"training_iteration\": 15,\n    \"trial_id\": \"4609f_00009\",\n    \"date\": \"2023-08-22_12-31-50\",\n    \"timestamp\": 1692707510,\n    \"time_total_s\": 793.7126927375793,\n    \"pid\": 2848490,\n    \"hostname\": \"dl\",\n    \"node_ip\": \"141.68.100.65\",\n    \"config\": {\n      \"epochs\": 15,\n      \"learning_rate\": 0.001,\n      \"batch_size\": 32,\n      \"l1\": 64\n    },\n    \"time_since_restore\": 793.7126927375793,\n    \"iterations_since_restore\": 15,\n    \"experiment_tag\": \"9_batch_size=32,epochs=15\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1692707510.386062,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.85525,\n      \"min\": 0.6764166666666667,\n      \"avg\": 0.8094111111111109,\n      \"last\": 0.8526666666666667,\n      \"last-5-avg\": 0.8463666666666667,\n      \"last-10-avg\": 0.8345583333333332\n    },\n    \"mean_val_loss\": {\n      \"max\": 1.2371817019780478,\n      \"min\": 0.4060302222569784,\n      \"avg\": 0.5497999069955614,\n      \"last\": 0.4060302222569784,\n      \"last-5-avg\": 0.42593973445892336,\n      \"last-10-avg\": 0.45708460956017183\n    },\n    \"time_this_iter_s\": {\n      \"max\": 63.51195788383484,\n      \"min\": 44.323787212371826,\n      \"avg\": 52.91417951583862,\n      \"last\": 62.338561058044434,\n      \"last-5-avg\": 56.6442626953125,\n      \"last-10-avg\": 53.174599933624265\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 793.7126927375793,\n      \"min\": 60.58080053329468,\n      \"avg\": 415.7034855206807,\n      \"last\": 793.7126927375793,\n      \"last-5-avg\": 672.0790143013,\n      \"last-10-avg\": 541.9139396667481\n    },\n    \"time_since_restore\": {\n      \"max\": 793.7126927375793,\n      \"min\": 60.58080053329468,\n      \"avg\": 415.7034855206807,\n      \"last\": 793.7126927375793,\n      \"last-5-avg\": 672.0790143013,\n      \"last-10-avg\": 541.9139396667481\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fea98ead65b7a33473feb2dbd194237fb473feafd44f3078264473feb5e353f7ced91473feb490b9af72016652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe9d0e560418937473fea08dfea27983c473fea6bdc8057619f473feaa740da740da7473feab6f46508dfea473fea98ead65b7a33473feb2dbd194237fb473feafd44f3078264473feb5e353f7ced91473feb490b9af72016652e\"\n      }\n    },\n    \"mean_val_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdd6b4aba1cac08473fdb29d651e098eb473fdb8b9f519f0fb4473fda2fd51be76c8b473fd9fc662f72015e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe0d6b579b4e81b473fe0377d743ece2a473fdf0401eead65b8473fddc2b761b4e81b473fdd58a33aaaaaab473fdd6b4aba1cac08473fdb29d651e098eb473fdb8b9f519f0fb4473fda2fd51be76c8b473fd9fc662f72015e652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740495d9d8e0000004740468012ca00000047404ed1c5da00000047404fc187d600000047404f2b55f8000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474049afb64c0000004740482404c6000000474048c34d4a0000004740497fec020000004740482c348a0000004740495d9d8e0000004740468012ca00000047404ed1c5da00000047404fc187d600000047404f2b55f8000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408189c831200000474082f1c95dc00000474084dee5bb600000474086dafe38c00000474088cdb398400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474073956e5d00000047407699eef5c00000474079b2589f00000047407ce2561f40000047407fe7dcb080000047408189c831200000474082f1c95dc00000474084dee5bb600000474086dafe38c00000474088cdb398400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847408189c831200000474082f1c95dc00000474084dee5bb600000474086dafe38c00000474088cdb398400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474073956e5d00000047407699eef5c00000474079b2589f00000047407ce2561f40000047407fe7dcb080000047408189c831200000474082f1c95dc00000474084dee5bb600000474086dafe38c00000474088cdb398400000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1692706716.6503587,\n  \"relative_logdir\": \"train_fashion_mnist_4609f_00009_9_batch_size=32,epochs=15_2023-08-22_12-06-07\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"saving_to\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595fe000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d1020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944affffffff8c0c73746f726167655f6d6f646594681a8c11436865636b706f696e7453746f726167659493944b01859452948c0472616e6b944b008c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f7079948875628c185f636865636b706f696e74735f746f5f636c65616e5f7570948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"_resources\": \"80054e2e\"\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_fashion_mnist\",\n  \"trial_id\": \"4609f_00012\",\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059593000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394888c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"_orig_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_orig_experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_local_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_remote_experiment_path\": null,\n  \"config\": {\n    \"epochs\": 20,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 16,\n    \"l1\": 64\n  },\n  \"_Trial__unresolved_config\": {\n    \"epochs\": 20,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 16,\n    \"l1\": 64\n  },\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"epochs\": 20\n  },\n  \"experiment_tag\": \"12_batch_size=16,epochs=20\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"mean_accuracy\": 0.8851666666666667,\n    \"mean_val_loss\": 0.318992173401018,\n    \"time_this_iter_s\": 63.93099665641785,\n    \"done\": true,\n    \"training_iteration\": 20,\n    \"trial_id\": \"4609f_00012\",\n    \"date\": \"2023-08-22_13-01-47\",\n    \"timestamp\": 1692709307,\n    \"time_total_s\": 1863.2209389209747,\n    \"pid\": 3032835,\n    \"hostname\": \"dl\",\n    \"node_ip\": \"141.68.100.65\",\n    \"config\": {\n      \"epochs\": 20,\n      \"learning_rate\": 0.001,\n      \"batch_size\": 16,\n      \"l1\": 64\n    },\n    \"time_since_restore\": 1863.2209389209747,\n    \"iterations_since_restore\": 20,\n    \"experiment_tag\": \"12_batch_size=16,epochs=20\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1692709307.5194829,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8865833333333333,\n      \"min\": 0.74825,\n      \"avg\": 0.8494374999999996,\n      \"last\": 0.8851666666666667,\n      \"last-5-avg\": 0.8827666666666666,\n      \"last-10-avg\": 0.8773\n    },\n    \"mean_val_loss\": {\n      \"max\": 0.7231627244551977,\n      \"min\": 0.31827534997463225,\n      \"avg\": 0.41839380793385206,\n      \"last\": 0.318992173401018,\n      \"last-5-avg\": 0.32919460942397516,\n      \"last-10-avg\": 0.3446958331711591\n    },\n    \"time_this_iter_s\": {\n      \"max\": 148.1736969947815,\n      \"min\": 63.23625326156616,\n      \"avg\": 93.16104694604871,\n      \"last\": 63.93099665641785,\n      \"last-5-avg\": 63.80419611930847,\n      \"last-10-avg\": 63.76105201244354\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 20,\n      \"min\": 1,\n      \"avg\": 10.5,\n      \"last\": 20,\n      \"last-5-avg\": 18.0,\n      \"last-10-avg\": 15.5\n    },\n    \"time_total_s\": {\n      \"max\": 1863.2209389209747,\n      \"min\": 133.67249202728271,\n      \"avg\": 1129.8015766978262,\n      \"last\": 1863.2209389209747,\n      \"last-5-avg\": 1735.507924079895,\n      \"last-10-avg\": 1576.5360060453415\n    },\n    \"time_since_restore\": {\n      \"max\": 1863.2209389209747,\n      \"min\": 133.67249202728271,\n      \"avg\": 1129.8015766978262,\n      \"last\": 1863.2209389209747,\n      \"last-5-avg\": 1735.507924079895,\n      \"last-10-avg\": 1576.5360060453415\n    },\n    \"iterations_since_restore\": {\n      \"max\": 20,\n      \"min\": 1,\n      \"avg\": 10.5,\n      \"last\": 20,\n      \"last-5-avg\": 18.0,\n      \"last-10-avg\": 15.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fec057619f0fb39473fec353f7ced9168473fec513cc1e098eb473fec5ee402bb0cf8473fec53490b9af720652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473febb020c49ba5e3473feb978d4fdf3b64473febfd44f3078264473fec0fb38a94d243473fec29a485cd7b90473fec057619f0fb39473fec353f7ced9168473fec513cc1e098eb473fec5ee402bb0cf8473fec53490b9af720652e\"\n      }\n    },\n    \"mean_val_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd65efabbb7a328473fd565bb362e6bdd473fd4c9ebab0b9af7473fd45e9f92d0e560473fd46a5e261bfd45652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd7f5e7c97fa89e473fd80187096b2dbd473fd6e61119942380473fd645f74ed65b7a473fd61fe08d242e6c473fd65efabbb7a328473fd565bb362e6bdd473fd4c9ebab0b9af7473fd45e9f92d0e560473fd46a5e261bfd45652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404fd8c29600000047404fd63b2c00000047405000137600000047404fdc5fea00000047404ff72ae6000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740504d0e1600000047404fbafe6e00000047404fa5594600000047404fb2c49c00000047404f9e3d8c00000047404fd8c29600000047404fd63b2c00000047405000137600000047404fdc5fea00000047404ff72ae6000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b104b114b124b134b14652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0b4b0c4b0d4b0e4b0f4b104b114b124b134b14652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740991f92d690000047409a1e44aff0000047409b1e45e750000047409c1d28e6a0000047409d1ce23dd00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740942b41f30000004740952919e67000004740962644b0a0000047409723dad580000047409820ccc1e000004740991f92d690000047409a1e44aff0000047409b1e45e750000047409c1d28e6a0000047409d1ce23dd00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740991f92d690000047409a1e44aff0000047409b1e45e750000047409c1d28e6a0000047409d1ce23dd00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740942b41f30000004740952919e67000004740962644b0a0000047409723dad580000047409820ccc1e000004740991f92d690000047409a1e44aff0000047409b1e45e750000047409c1d28e6a0000047409d1ce23dd00000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b104b114b124b134b14652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0b4b0c4b0d4b0e4b0f4b104b114b124b134b14652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1692707444.2818265,\n  \"relative_logdir\": \"train_fashion_mnist_4609f_00012_12_batch_size=16,epochs=20_2023-08-22_12-06-07\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"saving_to\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595fe000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d1020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944affffffff8c0c73746f726167655f6d6f646594681a8c11436865636b706f696e7453746f726167659493944b01859452948c0472616e6b944b008c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f7079948875628c185f636865636b706f696e74735f746f5f636c65616e5f7570948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"_resources\": \"80054e2e\"\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_fashion_mnist\",\n  \"trial_id\": \"4609f_00006\",\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059593000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394888c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"_orig_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_orig_experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_local_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_remote_experiment_path\": null,\n  \"config\": {\n    \"epochs\": 10,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 64,\n    \"l1\": 64\n  },\n  \"_Trial__unresolved_config\": {\n    \"epochs\": 10,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 64,\n    \"l1\": 64\n  },\n  \"evaluated_params\": {\n    \"batch_size\": 64,\n    \"epochs\": 10\n  },\n  \"experiment_tag\": \"6_batch_size=64,epochs=10\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"mean_accuracy\": 0.7834166666666667,\n    \"mean_val_loss\": 0.5848450971410629,\n    \"time_this_iter_s\": 27.066421508789062,\n    \"done\": true,\n    \"training_iteration\": 10,\n    \"trial_id\": \"4609f_00006\",\n    \"date\": \"2023-08-22_12-16-51\",\n    \"timestamp\": 1692706611,\n    \"time_total_s\": 271.65639209747314,\n    \"pid\": 2752043,\n    \"hostname\": \"dl\",\n    \"node_ip\": \"141.68.100.65\",\n    \"config\": {\n      \"epochs\": 10,\n      \"learning_rate\": 0.001,\n      \"batch_size\": 64,\n      \"l1\": 64\n    },\n    \"time_since_restore\": 271.65639209747314,\n    \"iterations_since_restore\": 10,\n    \"experiment_tag\": \"6_batch_size=64,epochs=10\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1692706611.2654793,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.78925,\n      \"min\": 0.46358333333333335,\n      \"avg\": 0.7184,\n      \"last\": 0.7834166666666667,\n      \"last-5-avg\": 0.7785,\n      \"last-10-avg\": 0.7184\n    },\n    \"mean_val_loss\": {\n      \"max\": 2.087053476495946,\n      \"min\": 0.5848450971410629,\n      \"avg\": 0.8804669085810795,\n      \"last\": 0.5848450971410629,\n      \"last-5-avg\": 0.6151601708632835,\n      \"last-10-avg\": 0.8804669085810793\n    },\n    \"time_this_iter_s\": {\n      \"max\": 31.563562870025635,\n      \"min\": 24.803568363189697,\n      \"avg\": 27.165639209747315,\n      \"last\": 27.066421508789062,\n      \"last-5-avg\": 26.76116180419922,\n      \"last-10-avg\": 27.165639209747315\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 10,\n      \"min\": 1,\n      \"avg\": 5.5,\n      \"last\": 10,\n      \"last-5-avg\": 8.0,\n      \"last-10-avg\": 5.5\n    },\n    \"time_total_s\": {\n      \"max\": 271.65639209747314,\n      \"min\": 31.563562870025635,\n      \"avg\": 151.04868268966675,\n      \"last\": 271.65639209747314,\n      \"last-5-avg\": 217.99212894439697,\n      \"last-10-avg\": 151.04868268966675\n    },\n    \"time_since_restore\": {\n      \"max\": 271.65639209747314,\n      \"min\": 31.563562870025635,\n      \"avg\": 151.04868268966675,\n      \"last\": 271.65639209747314,\n      \"last-5-avg\": 217.99212894439697,\n      \"last-10-avg\": 151.04868268966675\n    },\n    \"iterations_since_restore\": {\n      \"max\": 10,\n      \"min\": 1,\n      \"avg\": 5.5,\n      \"last\": 10,\n      \"last-5-avg\": 8.0,\n      \"last-10-avg\": 5.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe87c3ece2a5349473fe8c54a6921735f473fe8fa89e60f04c7473fe94189374bc6a8473fe911bfd44f3078652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fddab596de8ca12473fe463ab596de8ca473fe6900aec33e1f6473fe7a485cd7b900b473fe7e60f04c756b3473fe87c3ece2a5349473fe8c54a6921735f473fe8fa89e60f04c7473fe94189374bc6a8473fe911bfd44f3078652e\"\n      }\n    },\n    \"mean_val_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe4f8d539c9882c473fe41a42b0c415ca473fe3a323ef2620ae473fe2ffacff677d47473fe2b70d10ae4c41652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474000b24917d46cf0473ff5296d28000000473fec179c93931057473fe7f7583e20ae4c473fe627eff72620ae473fe4f8d539c9882c473fe41a42b0c415ca473fe3a323ef2620ae473fe2ffacff677d47473fe2b70d10ae4c41652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403b217970000000474039d4dff800000047403b1b6f8000000047403aab7f9800000047403b110100000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403f9045a800000047403a5c4520000000474038cdb6a800000047403bbba0c000000047403b63dda000000047403b217970000000474039d4dff800000047403b1b6f8000000047403aab7f9800000047403b110100000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b0a652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740649f6728000000474067da032700000047406b3d711700000047406e92e10a000000474070fa8095000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403f9045a800000047404cf64564000000474054ae905c00000047405b9d788c0000004740613b37fa0000004740649f6728000000474067da032700000047406b3d711700000047406e92e10a000000474070fa8095000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740649f6728000000474067da032700000047406b3d711700000047406e92e10a000000474070fa8095000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403f9045a800000047404cf64564000000474054ae905c00000047405b9d788c0000004740613b37fa0000004740649f6728000000474067da032700000047406b3d711700000047406e92e10a000000474070fa8095000000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b0a652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1692706339.5760198,\n  \"relative_logdir\": \"train_fashion_mnist_4609f_00006_6_batch_size=64,epochs=10_2023-08-22_12-06-07\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"saving_to\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595fe000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d1020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944affffffff8c0c73746f726167655f6d6f646594681a8c11436865636b706f696e7453746f726167659493944b01859452948c0472616e6b944b008c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f7079948875628c185f636865636b706f696e74735f746f5f636c65616e5f7570948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"_resources\": \"80054e2e\"\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_fashion_mnist\",\n  \"trial_id\": \"4609f_00005\",\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059593000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394888c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"_orig_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_orig_experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_local_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_remote_experiment_path\": null,\n  \"config\": {\n    \"epochs\": 10,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 32,\n    \"l1\": 64\n  },\n  \"_Trial__unresolved_config\": {\n    \"epochs\": 10,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 32,\n    \"l1\": 64\n  },\n  \"evaluated_params\": {\n    \"batch_size\": 32,\n    \"epochs\": 10\n  },\n  \"experiment_tag\": \"5_batch_size=32,epochs=10\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"mean_accuracy\": 0.8319166666666666,\n    \"mean_val_loss\": 0.46284767119089765,\n    \"time_this_iter_s\": 64.17361760139465,\n    \"done\": true,\n    \"training_iteration\": 10,\n    \"trial_id\": \"4609f_00005\",\n    \"date\": \"2023-08-22_12-18-15\",\n    \"timestamp\": 1692706695,\n    \"time_total_s\": 481.10398268699646,\n    \"pid\": 2713116,\n    \"hostname\": \"dl\",\n    \"node_ip\": \"141.68.100.65\",\n    \"config\": {\n      \"epochs\": 10,\n      \"learning_rate\": 0.001,\n      \"batch_size\": 32,\n      \"l1\": 64\n    },\n    \"time_since_restore\": 481.10398268699646,\n    \"iterations_since_restore\": 10,\n    \"experiment_tag\": \"5_batch_size=32,epochs=10\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1692706695.5944328,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8319166666666666,\n      \"min\": 0.6673333333333333,\n      \"avg\": 0.7879666666666664,\n      \"last\": 0.8319166666666666,\n      \"last-5-avg\": 0.8204166666666666,\n      \"last-10-avg\": 0.7879666666666666\n    },\n    \"mean_val_loss\": {\n      \"max\": 1.1447234811782836,\n      \"min\": 0.46284767119089765,\n      \"avg\": 0.6091414545774461,\n      \"last\": 0.46284767119089765,\n      \"last-5-avg\": 0.4958229316870371,\n      \"last-10-avg\": 0.6091414545774461\n    },\n    \"time_this_iter_s\": {\n      \"max\": 64.17361760139465,\n      \"min\": 36.627835512161255,\n      \"avg\": 48.11039826869964,\n      \"last\": 64.17361760139465,\n      \"last-5-avg\": 52.43509469032288,\n      \"last-10-avg\": 48.11039826869965\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 10,\n      \"min\": 1,\n      \"avg\": 5.5,\n      \"last\": 10,\n      \"last-5-avg\": 8.0,\n      \"last-10-avg\": 5.5\n    },\n    \"time_total_s\": {\n      \"max\": 481.10398268699646,\n      \"min\": 45.34549641609192,\n      \"avg\": 250.0312442302704,\n      \"last\": 481.10398268699646,\n      \"last-5-avg\": 372.29522666931155,\n      \"last-10-avg\": 250.03124423027037\n    },\n    \"time_since_restore\": {\n      \"max\": 481.10398268699646,\n      \"min\": 45.34549641609192,\n      \"avg\": 250.0312442302704,\n      \"last\": 481.10398268699646,\n      \"last-5-avg\": 372.29522666931155,\n      \"last-10-avg\": 250.03124423027037\n    },\n    \"iterations_since_restore\": {\n      \"max\": 10,\n      \"min\": 1,\n      \"avg\": 5.5,\n      \"last\": 10,\n      \"last-5-avg\": 8.0,\n      \"last-10-avg\": 5.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe9d65b7a328470473fea28f5c28f5c29473fea444444444444473fea619f0fb38a95473fea9f0fb38a94d2652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe55acb6f46508e473fe80369d0369d03473fe8d9c54a692173473fe9222222222222473fe987d9c54a6921473fe9d65b7a328470473fea28f5c28f5c29473fea444444444444473fea619f0fb38a95473fea9f0fb38a94d2652e\"\n      }\n    },\n    \"mean_val_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe0ec8eed555555473fe0264b032846ff473fdfd4c150aec33e473fdf100f7ee402bb473fdd9f4bd6b2dbd2652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff250c991a9fbe7473fe68c508619f0fb473fe3fdeda6a7ef9e473fe2a183dbb0cf88473fe1caa0c32846ff473fe0ec8eed555555473fe0264b032846ff473fdfd4c150aec33e473fdf100f7ee402bb473fdd9f4bd6b2dbd2652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474049cb24ac00000047404954e43c00000047404948c9c6000000474046976a220000004740500b1c8d000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474046ac393a000000474042505cea00000047404428343c00000047404801ceaa00000047404850405a000000474049cb24ac00000047404954e43c00000047404948c9c6000000474046976a220000004740500b1c8d000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b0a652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070e83fc200000047407412dc498000004740773bf58240000047407a0ee2c680000047407e11a9e9c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474046ac393a0000004740547e4b1200000047405e92653000000047406549a64280000047406b5db659000000474070e83fc200000047407412dc498000004740773bf58240000047407a0ee2c680000047407e11a9e9c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070e83fc200000047407412dc498000004740773bf58240000047407a0ee2c680000047407e11a9e9c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474046ac393a0000004740547e4b1200000047405e92653000000047406549a64280000047406b5db659000000474070e83fc200000047407412dc498000004740773bf58240000047407a0ee2c680000047407e11a9e9c00000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b0a652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1692706214.4687665,\n  \"relative_logdir\": \"train_fashion_mnist_4609f_00005_5_batch_size=32,epochs=10_2023-08-22_12-06-07\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"saving_to\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595fe000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d1020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944affffffff8c0c73746f726167655f6d6f646594681a8c11436865636b706f696e7453746f726167659493944b01859452948c0472616e6b944b008c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f7079948875628c185f636865636b706f696e74735f746f5f636c65616e5f7570948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"_resources\": \"80054e2e\"\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_fashion_mnist\",\n  \"trial_id\": \"4609f_00008\",\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059593000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394888c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"_orig_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_orig_experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_local_experiment_path\": \"/home/hammerer@ab.ba.ba-ravensburg.de/fashion-tuning/tune_runs/e3/train_fashion_mnist_2023-08-22_12-06-06\",\n  \"_remote_experiment_path\": null,\n  \"config\": {\n    \"epochs\": 15,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 16,\n    \"l1\": 64\n  },\n  \"_Trial__unresolved_config\": {\n    \"epochs\": 15,\n    \"learning_rate\": 0.001,\n    \"batch_size\": 16,\n    \"l1\": 64\n  },\n  \"evaluated_params\": {\n    \"batch_size\": 16,\n    \"epochs\": 15\n  },\n  \"experiment_tag\": \"8_batch_size=16,epochs=15\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740200000000000008c034750559447400000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"mean_accuracy\": 0.8706666666666667,\n    \"mean_val_loss\": 0.3584909804016352,\n    \"time_this_iter_s\": 98.72393751144409,\n    \"done\": true,\n    \"training_iteration\": 15,\n    \"trial_id\": \"4609f_00008\",\n    \"date\": \"2023-08-22_12-50-57\",\n    \"timestamp\": 1692708657,\n    \"time_total_s\": 2003.1559567451477,\n    \"pid\": 2836432,\n    \"hostname\": \"dl\",\n    \"node_ip\": \"141.68.100.65\",\n    \"config\": {\n      \"epochs\": 15,\n      \"learning_rate\": 0.001,\n      \"batch_size\": 16,\n      \"l1\": 64\n    },\n    \"time_since_restore\": 2003.1559567451477,\n    \"iterations_since_restore\": 15,\n    \"experiment_tag\": \"8_batch_size=16,epochs=15\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1692708657.2070384,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.87325,\n      \"min\": 0.75475,\n      \"avg\": 0.8351555555555558,\n      \"last\": 0.8706666666666667,\n      \"last-5-avg\": 0.8699333333333333,\n      \"last-10-avg\": 0.8561833333333333\n    },\n    \"mean_val_loss\": {\n      \"max\": 0.7269423571427663,\n      \"min\": 0.35666148552298543,\n      \"avg\": 0.46256067914168025,\n      \"last\": 0.3584909804016352,\n      \"last-5-avg\": 0.3677957500755787,\n      \"last-10-avg\": 0.4027166964883605\n    },\n    \"time_this_iter_s\": {\n      \"max\": 164.99994015693665,\n      \"min\": 98.72393751144409,\n      \"avg\": 133.5437304496765,\n      \"last\": 98.72393751144409,\n      \"last-5-avg\": 139.04589157104493,\n      \"last-10-avg\": 139.74928188323975\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_total_s\": {\n      \"max\": 2003.1559567451477,\n      \"min\": 136.93158411979675,\n      \"avg\": 1043.320992231369,\n      \"last\": 2003.1559567451477,\n      \"last-5-avg\": 1736.1292063713074,\n      \"last-10-avg\": 1379.735949587822\n    },\n    \"time_since_restore\": {\n      \"max\": 2003.1559567451477,\n      \"min\": 136.93158411979675,\n      \"avg\": 1043.320992231369,\n      \"last\": 2003.1559567451477,\n      \"last-5-avg\": 1736.1292063713074,\n      \"last-10-avg\": 1379.735949587822\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473feb99999999999a473febd7b900aec33e473febf1a9fbe76c8b473febf0fb38a94d24473febdc8057619f10652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fea5cd7b900aec3473feaef9db22d0e56473feb0da740da740e473feb44f3078263ab473feb2b020c49ba5e473feb99999999999a473febd7b900aec33e473febf1a9fbe76c8b473febf0fb38a94d24473febdc8057619f10652e\"\n      }\n    },\n    \"mean_val_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd8fcd84cd0e560473fd7c86a7caec33e473fd727824b078264473fd6d38ab2041893473fd6f184272f1aa0652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdf47828ea7ef9e473fdcb4d72e11bfd4473fdb48a03a237fa9473fda7bea0ea7ef9e473fda4a628f2dbd19473fd8fcd84cd0e560473fd7c86a7caec33e473fd727824b078264473fd6d38ab2041893473fd6f184272f1aa0652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847406150b429800000474060cb66fb0000004740649fff82800000474063d41292000000474058ae54fe000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405e6f0c6c000000474063f4c85b0000004740616277e6000000474061c2eb6880000047406176bb9480000047406150b429800000474060cb66fb0000004740649fff82800000474063d41292000000474058ae54fe000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847409699cb41500000474098b33820b0000047409b47381100000047409dc1ba6340000047409f4c9fb3200000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474086bb2fa8c0000047408bb861bf800000474090087fdc80000047409240dd499000004740946fb4bc20000047409699cb41500000474098b33820b0000047409b47381100000047409dc1ba6340000047409f4c9fb3200000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847409699cb41500000474098b33820b0000047409b47381100000047409dc1ba6340000047409f4c9fb3200000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474086bb2fa8c0000047408bb861bf800000474090087fdc80000047409240dd499000004740946fb4bc20000047409699cb41500000474098b33820b0000047409b47381100000047409dc1ba6340000047409f4c9fb3200000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1692706654.032497,\n  \"relative_logdir\": \"train_fashion_mnist_4609f_00008_8_batch_size=16,epochs=15_2023-08-22_12-06-07\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"train_fashion_mnist_2023-08-22_12-06-06\",\n  \"saving_to\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595fe000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d1020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944affffffff8c0c73746f726167655f6d6f646594681a8c11436865636b706f696e7453746f726167659493944b01859452948c0472616e6b944b008c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f7079948875628c185f636865636b706f696e74735f746f5f636c65616e5f7570948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"_resources\": \"80054e2e\"\n}"
  ],
  "runner_data": {
    "_earliest_stopping_actor": 9852679.92668881,
    "_actor_cleanup_timeout": 600,
    "_actor_force_cleanup_timeout": 10,
    "_reuse_actors": false,
    "_chdir_to_trial_dir": false,
    "_buffer_length": 1,
    "_buffer_min_time_s": 0.0,
    "_buffer_max_time_s": 100.0,
    "_max_pending_trials": 16,
    "_metric": null,
    "_total_time": 11751.461609125137,
    "_iteration": 30847,
    "_has_errored": false,
    "_fail_fast": false,
    "_print_trial_errors": true,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_start_time": 1692705966.808403,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2023-08-22_12-06-06",
    "_checkpoint_period": "auto",
    "_trial_checkpoint_config": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "800595ea000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b7394898c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b657273948975622e"
    },
    "_resumed": false,
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1692705966.808403,
    "timestamp": -Infinity
  }
}